{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'NonlinearAlignment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-10467fc395cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mNonlinearAlignment\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mleastsq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'NonlinearAlignment'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "import NonlinearAlignment as na\n",
    "from scipy.optimize import leastsq\n",
    "from collections import defaultdict\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Earth_gravity_model(sat_state, dt):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates next point for generlized coordintes\n",
    "    coord = np.array([x, y, z])\n",
    "    speed = np.array([Vx, Vy, Vz])\n",
    "    sat_state = np.array([x, y, z, Vx, Vy, Vz])\n",
    "    dt - time step    \n",
    "    \"\"\"\n",
    "    \n",
    "    coord = sat_state[:3]\n",
    "    speed = sat_state[3:]\n",
    "    r = np.linalg.norm(coord)       # distance to satellite\n",
    "    a_abs = (G * M) / (r ** 2)      # acceleration absolute value\n",
    "    a = -(coord / r) * a_abs\n",
    "    result_speed = speed + a * dt\n",
    "    result_coord = coord + (speed + result_speed) / 2 * dt\n",
    "    return np.concatenate([result_coord, result_speed])\n",
    "\n",
    "\n",
    "\n",
    "def iterative_trajectory_modelling(model, start_state, t_simulation, dt):\n",
    "    \n",
    "    \"\"\"\n",
    "    Iterating Earth_gravity_model or other function with same interface\n",
    "    \"\"\"\n",
    "    current_state = start_state\n",
    "    for step in range(int(t_simulation/ dt)):\n",
    "        current_state = model(sat_state=current_state, dt=dt)\n",
    "    current_state = model(current_state, dt=t_simulation % dt)\n",
    "    return current_state\n",
    "\n",
    "\n",
    "def inverse_iterative_trajectory_modelling(model, start_state, t_simulation, dt=1):\n",
    "    \"\"\"\n",
    "    predicting past states\n",
    "    \"\"\"\n",
    "    start_state[3:] *= -1\n",
    "    end_state = iterative_trajectory_modelling(model, start_state, t_simulation, dt)\n",
    "    end_state[3:] *= -1\n",
    "    return end_state\n",
    "\n",
    "\n",
    "def time_state(row):\n",
    "    time = row['epoch']\n",
    "    state = row[state_cols].values\n",
    "    return time, state\n",
    "        \n",
    "    \"\"\"\n",
    "    Predicts generalized coordinates for the future or the past \n",
    "    using Eath Gravity Model\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = defaultdict(lambda: {})\n",
    "    if begin_row is not None:\n",
    "        current_t, current_state = begin_t, begin_state = time_state(begin_row)\n",
    "        for t in t_new:\n",
    "            if t >= current_t:\n",
    "                current_state = iterative_trajectory_modelling(\n",
    "                    Earth_gravity_model, current_state * 1000, (t - current_t) / 10 ** 9,\n",
    "                    dt=dt) / 1000\n",
    "                current_t = t\n",
    "                pred[current_t]['forward'] = {'pred': current_state, 'sim_duration': current_t - begin_t}\n",
    "                \n",
    "    if end_row is not None:\n",
    "        current_t, current_state = end_t, end_state = time_state(end_row)\n",
    "        for t in t_new[::-1]:\n",
    "            if t <= current_t:\n",
    "                current_state = inverse_iterative_trajectory_modelling(\n",
    "                    Earth_gravity_model, current_state * 1000, (current_t - t) / 10 ** 9,\n",
    "                    dt=dt) / 1000\n",
    "                current_t = t\n",
    "                pred[current_t]['backward'] = {'pred': current_state, 'sim_duration': end_t - current_t}\n",
    "                \n",
    "    segment_df = []\n",
    "    for t in sorted(pred.keys()):\n",
    "        assert len(pred[t]) > 0\n",
    "        t_pred = np.zeros(6)\n",
    "        t_weights_sum = 0\n",
    "        \n",
    "        for simulation, simulation_res in pred[t].items():\n",
    "            assert simulation_res['sim_duration'] >= 0\n",
    "            weight = 1 / (simulation_res['sim_duration'] + 1)\n",
    "            t_pred += simulation_res['pred'] * weight\n",
    "            t_weights_sum += weight\n",
    "            \n",
    "        segment_df.append(np.concatenate([[t], t_pred / t_weights_sum]))\n",
    "    return segment_df\n",
    "\n",
    "def sparse_pred_to_dense(sparse_sat_data, t_new, dt):\n",
    "    \"\"\"\n",
    "    Fill the values in points between the sparse data\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    first_row = sparse_sat_data.iloc[0]\n",
    "    # predict before the first sparse point\n",
    "    result.extend(predict_segment(None, first_row, t_new[t_new < first_row['epoch']], dt=dt))\n",
    "    \n",
    "    for row_id in range(len(sparse_sat_data) - 1):\n",
    "        begin_row = sparse_sat_data.iloc[row_id]\n",
    "        end_row = sparse_sat_data.iloc[row_id + 1]\n",
    "        segment = t_new[(t_new >= begin_row['epoch']) & (t_new < end_row['epoch'])]\n",
    "        result.extend(predict_segment(begin_row, end_row, segment, dt=dt))\n",
    "    result.extend(predict_segment(end_row, None, t_new[t_new >= end_row['epoch']], dt=dt))\n",
    "    return pd.DataFrame(result, columns=['t',] + state_cols)\n",
    "\n",
    "\n",
    "def get_key_points(t, x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Basic function used in ZeroKeypointsGenerator\n",
    "    finding t: x(t)=0 and filtering the outliers\n",
    "    \"\"\"\n",
    "    spl = InterpolatedUnivariateSpline(t, x)\n",
    "    roots = spl.roots()\n",
    "    key_points = roots[1::2]\n",
    "    if len(key_points) < 3:\n",
    "        return key_points, np.zeros_like(key_points)\n",
    "    \n",
    "    outlier_scores = np.abs((key_points[2:] + key_points[:-2] - 2 * key_points[1:-1]) /\n",
    "                             key_points[1:-1])\n",
    "    np.pad(np.abs((key_points[2:] + key_points[:-2] - 2 * key_points[1:-1]) /\n",
    "                             key_points[1:-1]), (2, 2), mode = 'constant',constant_values=1)\n",
    "    \n",
    "    threshold = 3 * np.percentile(outlier_scores, 75) - 2 * np.percentile(outlier_scores, 25)\n",
    "    outliers = (np.convolve(np.pad(outlier_scores > threshold, (2, 2),mode = 'constant',constant_values=1), [1, 1, 1]) == 3)[2:-2]\n",
    "    return key_points, outliers\n",
    "\n",
    "\n",
    "def linear_params(t, x):\n",
    "    model_func = lambda params, t: (params[0] * t + params[1])\n",
    "    a = (x[-1] - x[0]) / (t[-1] - t[0])\n",
    "    b = x[0] - a * t[0]\n",
    "    init_params = (a, b)\n",
    "    return model_func, init_params\n",
    "\n",
    "\n",
    "def sinusoid_plus_linear_params(t, x):\n",
    "    model_func = lambda params, t: (params[0] *\n",
    "                                    np.sin(params[1] * t + params[2]) +\n",
    "                                    params[3] + t * params[4])\n",
    "    init_params = (np.std(x), 1/(t[-1] - t[0]), 0, np.mean(x), (x[-1] - x[0]) / (t[-1] - t[0]))\n",
    "    return model_func, init_params\n",
    "\n",
    "def pick_model_function(t, x):\n",
    "    \"\"\"\n",
    "    Selects linear or sinusoid + linear function \n",
    "    based on the number of time point\n",
    "    \"\"\"\n",
    "#     print(len(t))\n",
    "    if len(t) >= 10:\n",
    "        return sinusoid_plus_linear_params(t, x)\n",
    "    else:\n",
    "        return linear_params(t, x)\n",
    "\n",
    "def fit_curve(t, x, model_func, init_params):\n",
    "    def optimize_func(params):\n",
    "        return model_func(params, t) - x\n",
    "\n",
    "    ls_params = leastsq(optimize_func, init_params)[0]\n",
    "    return lambda x: model_func(ls_params, x)\n",
    "\n",
    "class ZeroKeypointsGenerator:\n",
    "    def __init__(self, anchor_feature):\n",
    "        self.anchor_feature = anchor_feature\n",
    "    \n",
    "    def get_sim_keypoints(self, sat_data):\n",
    "        return get_key_points(sat_data['epoch'], sat_data[self.anchor_feature + '_sim'])\n",
    "    \n",
    "    def get_gt_keypoints(self, sat_data):\n",
    "        return get_key_points(sat_data['epoch'], sat_data[self.anchor_feature])\n",
    "    \n",
    "\n",
    "class ShiftZeroKeypointsGenerator:\n",
    "    \"\"\"\n",
    "    Generating a lattice of keypoints (shifted from the roots of X(t)\n",
    "    by a portion of the oscillation period)\n",
    "    \"\"\"\n",
    "    def __init__(self, anchor_feature, alpha=1):\n",
    "        self.anchor_feature = anchor_feature\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def get_sim_keypoints(self, sat_data):\n",
    "        kp, outliers = get_key_points(sat_data['epoch'], sat_data[self.anchor_feature + '_sim'])\n",
    "        outliers = outliers[1:] | outliers[:-1]\n",
    "        period = kp[1:] - kp[:-1]\n",
    "        return kp[:-1] + period * self.alpha, outliers\n",
    "    \n",
    "    def get_gt_keypoints(self, sat_data):\n",
    "        kp, outliers = get_key_points(sat_data['epoch'], sat_data[self.anchor_feature])\n",
    "        outliers = outliers[1:] | outliers[:-1]\n",
    "        period = kp[1:] - kp[:-1]\n",
    "        return kp[:-1] + period * self.alpha, outliers\n",
    "    \n",
    "    \n",
    "def sine_alignment(sat_data, sat_id, kp_generator, train_t_max):\n",
    "    \"\"\"\n",
    "    Performs nonlinear stretching of the coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sat_data = sat_data[sat_data['epoch'] <= train_t_max]    \n",
    "    all_sim_kp, all_sim_kp_outliers = kp_generator.get_sim_keypoints(sat_data)\n",
    "    \n",
    "    # broken simulation handling\n",
    "    if sat_id == 481:\n",
    "        pred = sat_data[sat_data['epoch'] > train_t_max][['epoch'] + [c + '_sim' for c in state_cols]]\n",
    "        pred.columns =  ['t'] + state_cols\n",
    "        return pred\n",
    "        \n",
    "    train_gt_kp, train_gt_kp_outliers = kp_generator.get_gt_keypoints(train_sat_data)\n",
    "    \n",
    "    stretch_data = all_sim_kp[:len(train_gt_kp)], train_gt_kp\n",
    "    if len(train_gt_kp) >= 5:\n",
    "        use_kp = ~(all_sim_kp_outliers[:len(train_gt_kp)] | train_gt_kp_outliers)\n",
    "        stretch_data = (stretch_data[0][use_kp], stretch_data[1][use_kp])\n",
    "    time_stretch_function = fit_curve(*stretch_data,\n",
    "                                      *pick_model_function(all_sim_kp[:len(train_gt_kp)], train_gt_kp))\n",
    "\n",
    "    \n",
    "    keypoints = time_stretch_function(all_sim_kp)\n",
    "    train_keypoints = keypoints[keypoints < train_t_max]\n",
    "    test_keypoints = keypoints[len(train_keypoints):]\n",
    "    \n",
    "    \n",
    "    \n",
    "    sim_stretched_t = time_stretch_function(sat_data['epoch'])\n",
    "#    train_sim_stretched_t = sim_stretched_t[:len(train_sat_data)]\n",
    "    \n",
    "    pred = []\n",
    "#    gt = []\n",
    "    for feature in state_cols:\n",
    "        sim_feature = feature + '_sim'\n",
    "\n",
    "        \n",
    "        # values of simulation at all key points\n",
    "        all_kp_sim_feature = utils.resample(t=sim_stretched_t.values,\n",
    "                                              x=sat_data[sim_feature].values,\n",
    "                                              t_new=keypoints)\n",
    "        # values of simulation at train key points\n",
    "        train_kp_sim_feature = all_kp_sim_feature[:len(train_keypoints)]\n",
    "        \n",
    "        # ground truth values at train key points\n",
    "        train_kp_gt_feature = utils.resample(t=train_sat_data['epoch'],\n",
    "                                             x=train_sat_data[feature],\n",
    "                                             t_new=train_keypoints)\n",
    "\n",
    "        # difference between train and ground truth at train keypoints\n",
    "        train_diff = train_kp_gt_feature - train_kp_sim_feature\n",
    "#         kp_diff_func = lambda x: np.ones_like(x) * np.mean(train_diff)\n",
    "        kp_diff_func = fit_curve(train_keypoints, train_diff,\n",
    "                                  *linear_params(train_keypoints, train_diff))\n",
    "        pred_kp_diff = kp_diff_func(test_keypoints)\n",
    "\n",
    "\n",
    "        pred.append(pred_kp_diff + all_kp_sim_feature[len(train_keypoints):])\n",
    "    pred_df = pd.DataFrame(np.array(pred), index=state_cols).T\n",
    "    pred_df['epoch'] = test_keypoints\n",
    "    return pred_df\n",
    "\n",
    "def sine_alignment_part(sat_data, sat_id, kp_generator, train_t_max,train_t_min = 0):\n",
    "    '''\n",
    "    Args:\n",
    "    sat_id\n",
    "    kp_generator = instance of ShiftZeroKeypointsGenerator class\n",
    "    train_t_max = max time to train on\n",
    "    \n",
    "    \n",
    "    '''\n",
    "#    sat_data = utils.get_satellite_data(data, sat_id).reset_index(drop=True)\n",
    "#    sat_data = utils.remove_time_jumps_fast(sat_data)\n",
    "    \n",
    "    train_sat_data = sat_data[sat_data['epoch'] <= train_t_max]\n",
    "    m = int(train_t_min*train_sat_data.shape[0])\n",
    "    train_sat_data = train_sat_data[m:]\n",
    "    \n",
    "    all_sim_kp, all_sim_kp_outliers = kp_generator.get_sim_keypoints(sat_data)\n",
    "    # broken simulation handling\n",
    "    if sat_id == 481:\n",
    "        pred = sat_data[sat_data['epoch'] > train_t_max][['epoch'] + [c + '_sim' for c in state_cols]]\n",
    "        pred.columns =  ['t'] + state_cols\n",
    "        return pred\n",
    "        \n",
    "    train_gt_kp, train_gt_kp_outliers = kp_generator.get_gt_keypoints(train_sat_data)\n",
    "    \n",
    "    stretch_data = all_sim_kp[:len(train_gt_kp)], train_gt_kp #sim, followed by train  keypts\n",
    "    if len(train_gt_kp) >= 5:\n",
    "        use_kp = ~(all_sim_kp_outliers[:len(train_gt_kp)] | train_gt_kp_outliers)\n",
    "        stretch_data = (stretch_data[0][use_kp], stretch_data[1][use_kp])\n",
    "    time_stretch_function = fit_curve(*stretch_data,\n",
    "                                      *pick_model_function(all_sim_kp[:len(train_gt_kp)], train_gt_kp)) # ln=False\n",
    "    \n",
    "    keypoints = time_stretch_function(all_sim_kp)\n",
    "    train_keypoints = keypoints[keypoints < train_t_max]\n",
    "    test_keypoints = keypoints[len(train_keypoints):]\n",
    "    \n",
    "    sim_stretched_t = time_stretch_function(sat_data['epoch'])\n",
    "#    train_sim_stretched_t = sim_stretched_t[:len(train_sat_data)]\n",
    "    \n",
    "    pred = []\n",
    "#    gt = []\n",
    "    for feature in state_cols:\n",
    "        sim_feature = feature + '_sim'\n",
    "\n",
    "        \n",
    "        # values of simulation at all key points\n",
    "        all_kp_sim_feature = utils.resample(t=sim_stretched_t.values,\n",
    "                                              x=sat_data[sim_feature].values,\n",
    "                                              t_new=keypoints)\n",
    "        # values of simulation at train key points\n",
    "        train_kp_sim_feature = all_kp_sim_feature[:len(train_keypoints)]\n",
    "        \n",
    "        # ground truth values at train key points\n",
    "        train_kp_gt_feature = utils.resample(t=train_sat_data['epoch'],\n",
    "                                             x=train_sat_data[feature],\n",
    "                                             t_new=train_keypoints)\n",
    "\n",
    "        # difference between train and ground truth at train keypoints\n",
    "        train_diff = train_kp_gt_feature - train_kp_sim_feature\n",
    "#         kp_diff_func = lambda x: np.ones_like(x) * np.mean(train_diff)\n",
    "        kp_diff_func = fit_curve(train_keypoints, train_diff,\n",
    "                                  *linear_params(train_keypoints, train_diff))\n",
    "        pred_kp_diff = kp_diff_func(test_keypoints)\n",
    "\n",
    "\n",
    "        pred.append(pred_kp_diff + all_kp_sim_feature[len(train_keypoints):])\n",
    "    pred_df = pd.DataFrame(np.array(pred), index=state_cols).T\n",
    "    pred_df['epoch'] = test_keypoints\n",
    "    return pred_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>sat_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "      <th>x_sim</th>\n",
       "      <th>y_sim</th>\n",
       "      <th>z_sim</th>\n",
       "      <th>Vx_sim</th>\n",
       "      <th>Vy_sim</th>\n",
       "      <th>Vz_sim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01T00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>-8855.823863</td>\n",
       "      <td>13117.780146</td>\n",
       "      <td>-20728.353233</td>\n",
       "      <td>-0.908303</td>\n",
       "      <td>-3.808436</td>\n",
       "      <td>-2.022083</td>\n",
       "      <td>-8843.131454</td>\n",
       "      <td>13138.221690</td>\n",
       "      <td>-20741.615306</td>\n",
       "      <td>-0.907527</td>\n",
       "      <td>-3.804930</td>\n",
       "      <td>-2.024133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01T00:46:43.000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10567.672384</td>\n",
       "      <td>1619.746066</td>\n",
       "      <td>-24451.813271</td>\n",
       "      <td>-0.302590</td>\n",
       "      <td>-4.272617</td>\n",
       "      <td>-0.612796</td>\n",
       "      <td>-10555.500066</td>\n",
       "      <td>1649.289367</td>\n",
       "      <td>-24473.089556</td>\n",
       "      <td>-0.303704</td>\n",
       "      <td>-4.269816</td>\n",
       "      <td>-0.616468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01T01:33:26.001</td>\n",
       "      <td>0</td>\n",
       "      <td>-10578.684043</td>\n",
       "      <td>-10180.467460</td>\n",
       "      <td>-24238.280949</td>\n",
       "      <td>0.277435</td>\n",
       "      <td>-4.047522</td>\n",
       "      <td>0.723155</td>\n",
       "      <td>-10571.858472</td>\n",
       "      <td>-10145.939908</td>\n",
       "      <td>-24271.169776</td>\n",
       "      <td>0.274880</td>\n",
       "      <td>-4.046788</td>\n",
       "      <td>0.718768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      epoch  sat_id             x             y             z  \\\n",
       "id                                                                              \n",
       "0   2014-01-01T00:00:00.000       0  -8855.823863  13117.780146 -20728.353233   \n",
       "1   2014-01-01T00:46:43.000       0 -10567.672384   1619.746066 -24451.813271   \n",
       "2   2014-01-01T01:33:26.001       0 -10578.684043 -10180.467460 -24238.280949   \n",
       "\n",
       "          Vx        Vy        Vz         x_sim         y_sim         z_sim  \\\n",
       "id                                                                           \n",
       "0  -0.908303 -3.808436 -2.022083  -8843.131454  13138.221690 -20741.615306   \n",
       "1  -0.302590 -4.272617 -0.612796 -10555.500066   1649.289367 -24473.089556   \n",
       "2   0.277435 -4.047522  0.723155 -10571.858472 -10145.939908 -24271.169776   \n",
       "\n",
       "      Vx_sim    Vy_sim    Vz_sim  \n",
       "id                                \n",
       "0  -0.907527 -3.804930 -2.024133  \n",
       "1  -0.303704 -4.269816 -0.616468  \n",
       "2   0.274880 -4.046788  0.718768  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv', index_col= 'id')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(50)\n",
    "coord_cols = ['x', 'y', 'z']\n",
    "speed_cols = ['Vx', 'Vy', 'Vz']\n",
    "state_cols = coord_cols + speed_cols\n",
    "\n",
    "print('Loading data...')\n",
    "train_data = pd.read_csv('data/train.csv', index_col='id')\n",
    "train_data['epoch'] = pd.to_datetime(train_data['epoch']).values.astype(float)\n",
    "\n",
    "test_data = pd.read_csv('data/test.csv', index_col='id')\n",
    "test_data['epoch'] = pd.to_datetime(test_data['epoch']).values.astype(float)\n",
    "\n",
    "data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True)\n",
    "print('Data loaded.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-6fddf6417d04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msat_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_satellite_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msat_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msat_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_time_jumps_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msat_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_sat_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msat_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msat_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mtrain_t_max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_sim_kp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_sim_kp_outliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkp_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_sim_keypoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msat_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "sat_data = utils.get_satellite_data(data, sat_id).reset_index(drop=True)\n",
    "sat_data = utils.remove_time_jumps_fast(sat_data)\n",
    "train_sat_data = sat_data[sat_data['epoch'] <= train_t_max]    \n",
    "all_sim_kp, all_sim_kp_outliers = kp_generator.get_sim_keypoints(sat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
