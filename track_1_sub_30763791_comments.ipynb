{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline, UnivariateSpline\n",
    "from scipy.optimize import leastsq, least_squares\n",
    "import utils\n",
    "from collections import defaultdict\n",
    "from LinearAlignment import LinearAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(50)\n",
    "coord_cols = ['x', 'y', 'z']\n",
    "speed_cols = ['Vx', 'Vy', 'Vz']\n",
    "state_cols = coord_cols + speed_cols\n",
    "# anchor_cols = state_cols + ['distance', 'abs_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 6.6743e-11 # gravity constant\n",
    "M = 5.972e+24  # Earth mass\n",
    "\n",
    "# coord = np.array([x, y, z])\n",
    "# speed = np.array([Vx, Vy, Vz])\n",
    "# sat_state = np.array([x, y, z, Vx, Vy, Vz])\n",
    "def Earth_gravity_model(sat_state, dt):\n",
    "    \n",
    "    \"\"\"\n",
    "    predicts changes of the generalized coordinates of a satellite after time dt\n",
    "    assuming only motion within the Earth gravitational field\n",
    "    \n",
    "    sat_state - [6,1] vector of generalized coordinates\n",
    "    dt - time interval\n",
    "    \"\"\"\n",
    "    coord = sat_state[:3]\n",
    "    speed = sat_state[3:]\n",
    "    r = np.linalg.norm(coord)       # distance to satellite\n",
    "    a_abs = (G * M) / (r ** 2)      # acceleration absolutevalue\n",
    "    a = -(coord / r) * a_abs\n",
    "    result_speed = speed + a * dt\n",
    "    result_coord = coord + (speed + result_speed) / 2 * dt\n",
    "    return np.concatenate([result_coord, result_speed])\n",
    "\n",
    "\n",
    "\n",
    "def iterative_trajectory_modelling(model, start_state, t_simulation, dt):\n",
    "    \"\"\"\n",
    "    Iterating Earth_gravity_model or other function with same interface\n",
    "    \"\"\"\n",
    "    current_state = start_state\n",
    "    for step in range(int(t_simulation / dt)):\n",
    "        current_state = model(sat_state=current_state, dt=dt)\n",
    "    current_state = model(current_state, dt=t_simulation % dt)\n",
    "    return current_state\n",
    "\n",
    "\n",
    "def inverse_iterative_trajectory_modelling(model, start_state, t_simulation, dt=1):\n",
    "    \"\"\"\n",
    "    predicting past states\n",
    "    \"\"\"\n",
    "    start_state[3:] *= -1 #creating vector of backward velocities\n",
    "    end_state = iterative_trajectory_modelling(model, start_state, t_simulation, dt) # propagate the coordinates backward\n",
    "    end_state[3:] *= -1 #correct speeds for forward propagation\n",
    "    return end_state\n",
    "\n",
    "\n",
    "def time_state(row):\n",
    "    time = row['epoch']\n",
    "    state = row[state_cols].values\n",
    "    return time, state\n",
    "    \n",
    "def predict_segment(begin_row, end_row, t_new, dt):\n",
    "    pred = defaultdict(lambda: {})\n",
    "    \n",
    "    if begin_row is not None:\n",
    "        # propagate forward\n",
    "        current_t, current_state = begin_t, begin_state = time_state(begin_row)\n",
    "        for t in t_new:\n",
    "            if t >= current_t:\n",
    "                current_state = iterative_trajectory_modelling(\n",
    "                    Earth_gravity_model, current_state * 1000, (t - current_t) / 10 ** 9,\n",
    "                    dt=dt) / 1000\n",
    "                current_t = t\n",
    "                pred[current_t]['forward'] = {'pred': current_state, 'sim_duration': current_t - begin_t}\n",
    "                \n",
    "    if end_row is not None:\n",
    "        # propagate backward\n",
    "        current_t, current_state = end_t, end_state = time_state(end_row)\n",
    "        for t in t_new[::-1]:\n",
    "            if t <= current_t:\n",
    "                current_state = inverse_iterative_trajectory_modelling(\n",
    "                    Earth_gravity_model, current_state * 1000, (current_t - t) / 10 ** 9,\n",
    "                    dt=dt) / 1000\n",
    "                current_t = t\n",
    "                pred[current_t]['backward'] = {'pred': current_state, 'sim_duration': end_t - current_t}\n",
    "                \n",
    "    segment_df = []\n",
    "    for t in sorted(pred.keys()):\n",
    "        assert len(pred[t]) > 0\n",
    "        t_pred = np.zeros(6)\n",
    "        t_weights_sum = 0\n",
    "        \n",
    "        for simulation, simulation_res in pred[t].items():\n",
    "            assert simulation_res['sim_duration'] >= 0\n",
    "            weight = 1 / (simulation_res['sim_duration'] + 1)\n",
    "            t_pred += simulation_res['pred'] * weight\n",
    "            t_weights_sum += weight\n",
    "            \n",
    "        segment_df.append(np.concatenate([[t], t_pred / t_weights_sum]))\n",
    "    return segment_df\n",
    "\n",
    "def sparse_pred_to_dense(sparse_sat_data, t_new, dt):\n",
    "    \n",
    "    \n",
    "    result = []\n",
    "    first_row = sparse_sat_data.iloc[0]\n",
    "    result.extend(predict_segment(None, first_row, t_new[t_new < first_row['epoch']], dt=dt))\n",
    "    \n",
    "#     t_new_id_min = t_new_id_max = 0\n",
    "    for row_id in range(len(sparse_sat_data) - 1):\n",
    "        begin_row = sparse_sat_data.iloc[row_id]\n",
    "        end_row = sparse_sat_data.iloc[row_id + 1]\n",
    "        segment = t_new[(t_new >= begin_row['epoch']) & (t_new < end_row['epoch'])]\n",
    "        result.extend(predict_segment(begin_row, end_row, segment, dt=dt))\n",
    "    result.extend(predict_segment(end_row, None, t_new[t_new >= end_row['epoch']], dt=dt))\n",
    "    return pd.DataFrame(result, columns=['t',] + state_cols)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic function used in ZeroKeypointsGenerator\n",
    "# finding t: x(t)=0.\n",
    "def get_key_points(t, x):\n",
    "    spl = InterpolatedUnivariateSpline(t, x)\n",
    "    roots = spl.roots()\n",
    "    key_points = roots[1::2] # roots of the function spaced roughly by a period\n",
    "    if len(key_points) < 3:\n",
    "        return key_points, np.zeros_like(key_points)\n",
    "    \n",
    "    outlier_scores = np.abs((key_points[2:] + key_points[:-2] - 2 * key_points[1:-1]) /\n",
    "                             key_points[1:-1])\n",
    "    np.pad(np.abs((key_points[2:] + key_points[:-2] - 2 * key_points[1:-1]) /\n",
    "                             key_points[1:-1]), (2, 2))\n",
    "    \n",
    "    threshold = 3 * np.percentile(outlier_scores, 75) - 2 * np.percentile(outlier_scores, 25)\n",
    "    outliers = (np.convolve(np.pad(outlier_scores > threshold, (2, 2),constant_values=1), [1, 1, 1]) == 3)[2:-2]\n",
    "    return key_points, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a * x + b -> (x - b) / a\n",
    "def inverse_to_linear(func):\n",
    "    b = func(0)\n",
    "    a = func(1) - b\n",
    "    return lambda x: (x - b) / a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_params(t, x):\n",
    "    model_func = lambda params, t: (params[0] * t + params[1])\n",
    "    a = (x[-1] - x[0]) / (t[-1] - t[0])\n",
    "    b = x[0] - a * t[0]\n",
    "    init_params = (a, b)\n",
    "    return model_func, init_params\n",
    "\n",
    "# sinusoid + linear\n",
    "def sinusoid_plus_linear_params(t, x):\n",
    "    model_func = lambda params, t: (params[0] *\n",
    "                                    np.sin(params[1] * t + params[2]) +\n",
    "                                    params[3] + t * params[4])\n",
    "    init_params = (np.std(x), 1/(t[-1] - t[0]), 0, np.mean(x), (x[-1] - x[0]) / (t[-1] - t[0]))\n",
    "    return model_func, init_params\n",
    "\n",
    "def pick_model_function(t, x):\n",
    "#     print(len(t))\n",
    "    if len(t) >= 10:\n",
    "        return sinusoid_plus_linear_params(t, x)\n",
    "    else:\n",
    "        return linear_params(t, x)\n",
    "\n",
    "def fit_curve(t, x, model_func, init_params):\n",
    "    def optimize_func(params):\n",
    "        return model_func(params, t) - x\n",
    "\n",
    "    ls_params = leastsq(optimize_func, init_params)[0]\n",
    "    return lambda x: model_func(ls_params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroKeypointsGenerator:\n",
    "    def __init__(self, anchor_feature):\n",
    "        self.anchor_feature = anchor_feature\n",
    "    \n",
    "    def get_sim_keypoints(self, sat_data):\n",
    "        return get_key_points(sat_data['epoch'], sat_data[self.anchor_feature + '_sim'])\n",
    "    \n",
    "    def get_gt_keypoints(self, sat_data):\n",
    "        return get_key_points(sat_data['epoch'], sat_data[self.anchor_feature])\n",
    "    \n",
    "# generating a lattice of keypoints\n",
    "class ShiftZeroKeypointsGenerator:\n",
    "    def __init__(self, anchor_feature, alpha=1):\n",
    "        self.anchor_feature = anchor_feature\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def get_sim_keypoints(self, sat_data):\n",
    "        kp, outliers = get_key_points(sat_data['epoch'], sat_data[self.anchor_feature + '_sim'])\n",
    "        outliers = outliers[1:] | outliers[:-1] \n",
    "        period = kp[1:] - kp[:-1]\n",
    "        return kp[:-1] + period * self.alpha, outliers\n",
    "    \n",
    "    def get_gt_keypoints(self, sat_data):\n",
    "        kp, outliers = get_key_points(sat_data['epoch'], sat_data[self.anchor_feature])\n",
    "        outliers = outliers[1:] | outliers[:-1]\n",
    "        period = kp[1:] - kp[:-1]\n",
    "        return kp[:-1] + period * self.alpha, outliers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sine_alignment(sat_id, kp_generator, train_t_max):\n",
    "    \"\"\"\n",
    "    performs non-linear alignment of the simulated data\n",
    "    \"\"\"\n",
    "    sat_data = utils.get_satellite_data(data, sat_id).reset_index(drop=True) # load data for the satellite\n",
    "    sat_data = utils.remove_time_jumps_fast(sat_data) # remove effect of time jumps\n",
    "    \n",
    "    train_sat_data = sat_data[sat_data['epoch'] <= train_t_max] #select a train part of the data\n",
    "    \n",
    "    all_sim_kp, all_sim_kp_outliers = kp_generator.get_sim_keypoints(sat_data) #getting key points and outliers for simulation\n",
    "    # broken simulation handling\n",
    "    if sat_id == 481:\n",
    "        pred = sat_data[sat_data['epoch'] > train_t_max][['epoch'] + [c + '_sim' for c in state_cols]]\n",
    "        pred.columns =  ['t'] + state_cols\n",
    "        return pred\n",
    "        \n",
    "    train_gt_kp, train_gt_kp_outliers = kp_generator.get_gt_keypoints(train_sat_data) #getting key points and outliers for ground truth\n",
    "    \n",
    "    stretch_data = all_sim_kp[:len(train_gt_kp)], train_gt_kp # consider training part of the key points\n",
    "    if len(train_gt_kp) >= 5:\n",
    "        use_kp = ~(all_sim_kp_outliers[:len(train_gt_kp)] | train_gt_kp_outliers) # exclude outliers\n",
    "        stretch_data = (stretch_data[0][use_kp], stretch_data[1][use_kp])\n",
    "        \n",
    "    # find the function that maps simulated data key point to the key points \n",
    "    # of ground truth with either sinusoidal or linear function\n",
    "    time_stretch_function = fit_curve(*stretch_data,\n",
    "                                      *pick_model_function(all_sim_kp[:len(train_gt_kp)], train_gt_kp))\n",
    "\n",
    "    \n",
    "    keypoints = time_stretch_function(all_sim_kp)\n",
    "    train_keypoints = keypoints[keypoints < train_t_max]\n",
    "    test_keypoints = keypoints[len(train_keypoints):]\n",
    "    \n",
    "    \n",
    "    \n",
    "    sim_stretched_t = time_stretch_function(sat_data['epoch'])\n",
    "    train_sim_stretched_t = sim_stretched_t[:len(train_sat_data)]\n",
    "    \n",
    "    pred = []\n",
    "    gt = []\n",
    "    for feature in state_cols:\n",
    "        sim_feature = feature + '_sim'\n",
    "\n",
    "        \n",
    "        # values of simulation at all key points\n",
    "        all_kp_sim_feature = utils.resample(t=sim_stretched_t.values,\n",
    "                                              x=sat_data[sim_feature].values,\n",
    "                                              t_new=keypoints)\n",
    "        # values of simulation at train key points\n",
    "        train_kp_sim_feature = all_kp_sim_feature[:len(train_keypoints)]\n",
    "        \n",
    "        # ground truth values at train key points\n",
    "        train_kp_gt_feature = utils.resample(t=train_sat_data['epoch'],\n",
    "                                             x=train_sat_data[feature],\n",
    "                                             t_new=train_keypoints)\n",
    "\n",
    "        # difference between train and ground truth at train keypoints\n",
    "        train_diff = train_kp_gt_feature - train_kp_sim_feature\n",
    "#         kp_diff_func = lambda x: np.ones_like(x) * np.mean(train_diff)\n",
    "        kp_diff_func = fit_curve(train_keypoints, train_diff,\n",
    "                                  *linear_params(train_keypoints, train_diff))\n",
    "        pred_kp_diff = kp_diff_func(test_keypoints)\n",
    "\n",
    "\n",
    "        pred.append(pred_kp_diff + all_kp_sim_feature[len(train_keypoints):])\n",
    "    pred_df = pd.DataFrame(np.array(pred), index=state_cols).T\n",
    "    pred_df['epoch'] = test_keypoints\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_meta_prediction(predictions):\n",
    "#     for sat_id, sat_predictions in sorted(predictions.keys()):\n",
    "#         print(np.mean([p.values[:, 1:] for p in sat_predictions], axis=0))\n",
    "    result = [np.median([p.values[:, 1:] for p in sat_predictions], axis=0)\n",
    "              for sat_id, sat_predictions in sorted(predictions.items())]\n",
    "    result = np.concatenate(result)\n",
    "    return pd.DataFrame(result, columns=state_cols, index = test_data.index)\n",
    "\n",
    "def pick_self_meta_prediction(predictions):\n",
    "#     for sat_id, sat_predictions in sorted(predictions.keys()):\n",
    "#         print(np.mean([p.values[:, 1:] for p in sat_predictions], axis=0))\n",
    "    result = []\n",
    "    for sat_id, sat_predictions in sorted(predictions.items()):\n",
    "        sat_pred = np.zeros_like(sat_predictions[0][state_cols])\n",
    "        for i, p in enumerate(sat_predictions):\n",
    "            sat_pred[:, i] = p[state_cols[i]].values\n",
    "        result.append(sat_pred)\n",
    "    result = np.concatenate(result)\n",
    "    return pd.DataFrame(result, columns=state_cols, index = test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv', index_col='id')\n",
    "train_data['epoch'] = pd.to_datetime(train_data['epoch']).astype(int)\n",
    "\n",
    "test_data = pd.read_csv('data/Track 1/test.csv', index_col='id')\n",
    "test_data['epoch'] = pd.to_datetime(test_data['epoch']).astype(int)\n",
    "\n",
    "data = pd.concat([train_data, test_data], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This modelling takes about 10 hours on my old laptop.\n",
    "for sat_id in tqdm(test_data['sat_id'].unique()):\n",
    "    try:\n",
    "        train_t = utils.get_satellite_data(train_data, sat_id)['epoch']\n",
    "        test_t = utils.get_satellite_data(test_data, sat_id)['epoch']\n",
    "        pred_dfs = []\n",
    "        sparse_pred_dfs = []\n",
    "        # running sine_alignment for different lattices:\n",
    "        # different alphas and anchor features\n",
    "        for anchor in state_cols:\n",
    "            for alpha in np.linspace(0, 1, 100)[1:]:\n",
    "                pred_df = sine_alignment(sat_id, ShiftZeroKeypointsGenerator(anchor, alpha), train_t.max())\n",
    "                sparse_pred_dfs.append(pred_df)\n",
    "        sparse_pred = pd.concat(sparse_pred_dfs).sort_values('epoch').reset_index(drop=True)\n",
    "        dense_pred = sparse_pred_to_dense(sparse_pred, test_t, dt=8)\n",
    "        all_predictions_shiftzero_kp[sat_id] = dense_pred\n",
    "        #backup save\n",
    "        with open(f'data/Track 1/tmp/shiftzero_keypoints/{sat_id}.pkl', 'wb') as f:\n",
    "            pkl.dump(dense_pred, f)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satellite 481 has broken simulation.\n",
    "all_predictions_shiftzero_kp[481] = sine_alignment(481, ShiftZeroKeypointsGenerator('x', 0), train_t.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shiftzero_kp = pd.concat([all_predictions_shiftzero_kp[k]\n",
    "                            for k in sorted(all_predictions_shiftzero_kp.keys())])[state_cols]\n",
    "df_shiftzero_kp.index = test_data.index\n",
    "# saving submission csv\n",
    "df_shiftzero_kp.to_csv('data/Track 1/submissions/sine_alignment/shiftzero_kp.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
