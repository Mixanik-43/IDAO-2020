{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXyqz1FjJE6W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'utils_edit_mb.ipynb' matched no files\r\n",
      "This application is used to convert notebook files (*.ipynb) to various other\r\n",
      "formats.\r\n",
      "\r\n",
      "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\r\n",
      "\r\n",
      "Options\r\n",
      "-------\r\n",
      "\r\n",
      "Arguments that take values are actually convenience aliases to full\r\n",
      "Configurables, whose aliases are listed on the help line. For more information\r\n",
      "on full configurables, see '--help-all'.\r\n",
      "\r\n",
      "--debug\r\n",
      "    set log level to logging.DEBUG (maximize logging output)\r\n",
      "--generate-config\r\n",
      "    generate default config file\r\n",
      "-y\r\n",
      "    Answer yes to any questions instead of prompting.\r\n",
      "--execute\r\n",
      "    Execute the notebook prior to export.\r\n",
      "--allow-errors\r\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\r\n",
      "--stdin\r\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\r\n",
      "--stdout\r\n",
      "    Write notebook output to stdout instead of files.\r\n",
      "--inplace\r\n",
      "    Run nbconvert in place, overwriting the existing notebook (only \r\n",
      "    relevant when converting to notebook format)\r\n",
      "--clear-output\r\n",
      "    Clear output of current file and save in place, \r\n",
      "    overwriting the existing notebook.\r\n",
      "--no-prompt\r\n",
      "    Exclude input and output prompts from converted document.\r\n",
      "--no-input\r\n",
      "    Exclude input cells and output prompts from converted document. \r\n",
      "    This mode is ideal for generating code-free reports.\r\n",
      "--log-level=<Enum> (Application.log_level)\r\n",
      "    Default: 30\r\n",
      "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\r\n",
      "    Set the log level by value or name.\r\n",
      "--config=<Unicode> (JupyterApp.config_file)\r\n",
      "    Default: ''\r\n",
      "    Full path of a config file.\r\n",
      "--to=<Unicode> (NbConvertApp.export_format)\r\n",
      "    Default: 'html'\r\n",
      "    The export format to be used, either one of the built-in formats\r\n",
      "    ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf',\r\n",
      "    'python', 'rst', 'script', 'slides'] or a dotted object name that represents\r\n",
      "    the import path for an `Exporter` class\r\n",
      "--template=<Unicode> (TemplateExporter.template_file)\r\n",
      "    Default: ''\r\n",
      "    Name of the template file to use\r\n",
      "--writer=<DottedObjectName> (NbConvertApp.writer_class)\r\n",
      "    Default: 'FilesWriter'\r\n",
      "    Writer class used to write the  results of the conversion\r\n",
      "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\r\n",
      "    Default: ''\r\n",
      "    PostProcessor class used to write the results of the conversion\r\n",
      "--output=<Unicode> (NbConvertApp.output_base)\r\n",
      "    Default: ''\r\n",
      "    overwrite base name use for output files. can only be used when converting\r\n",
      "    one notebook at a time.\r\n",
      "--output-dir=<Unicode> (FilesWriter.build_directory)\r\n",
      "    Default: ''\r\n",
      "    Directory to write output(s) to. Defaults to output to the directory of each\r\n",
      "    notebook. To recover previous default behaviour (outputting to the current\r\n",
      "    working directory) use . as the flag value.\r\n",
      "--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\r\n",
      "    Default: ''\r\n",
      "    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,\r\n",
      "    but can be any url pointing to a copy  of reveal.js.\r\n",
      "    For speaker notes to work, this must be a relative path to a local  copy of\r\n",
      "    reveal.js: e.g., \"reveal.js\".\r\n",
      "    If a relative path is given, it must be a subdirectory of the current\r\n",
      "    directory (from which the server is run).\r\n",
      "    See the usage documentation\r\n",
      "    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-\r\n",
      "    slideshow) for more details.\r\n",
      "--nbformat=<Enum> (NotebookExporter.nbformat_version)\r\n",
      "    Default: 4\r\n",
      "    Choices: [1, 2, 3, 4]\r\n",
      "    The nbformat version to write. Use this to downgrade notebooks.\r\n",
      "\r\n",
      "To see all available configurables, use `--help-all`\r\n",
      "\r\n",
      "Examples\r\n",
      "--------\r\n",
      "\r\n",
      "    The simplest way to use nbconvert is\r\n",
      "    \r\n",
      "    > jupyter nbconvert mynotebook.ipynb\r\n",
      "    \r\n",
      "    which will convert mynotebook.ipynb to the default format (probably HTML).\r\n",
      "    \r\n",
      "    You can specify the export format with `--to`.\r\n",
      "    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\r\n",
      "    \r\n",
      "    > jupyter nbconvert --to latex mynotebook.ipynb\r\n",
      "    \r\n",
      "    Both HTML and LaTeX support multiple output templates. LaTeX includes\r\n",
      "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\r\n",
      "    can specify the flavor of the format used.\r\n",
      "    \r\n",
      "    > jupyter nbconvert --to html --template basic mynotebook.ipynb\r\n",
      "    \r\n",
      "    You can also pipe the output to stdout, rather than a file\r\n",
      "    \r\n",
      "    > jupyter nbconvert mynotebook.ipynb --stdout\r\n",
      "    \r\n",
      "    PDF is generated via latex\r\n",
      "    \r\n",
      "    > jupyter nbconvert mynotebook.ipynb --to pdf\r\n",
      "    \r\n",
      "    You can get (and serve) a Reveal.js-powered slideshow\r\n",
      "    \r\n",
      "    > jupyter nbconvert myslides.ipynb --to slides --post serve\r\n",
      "    \r\n",
      "    Multiple notebooks can be given at the command line in a couple of \r\n",
      "    different ways:\r\n",
      "    \r\n",
      "    > jupyter nbconvert notebook*.ipynb\r\n",
      "    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\r\n",
      "    \r\n",
      "    or you can specify the notebooks list in a config file, containing::\r\n",
      "    \r\n",
      "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\r\n",
      "    \r\n",
      "    > jupyter nbconvert --config mycfg.py\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import splrep, splev\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from fbprophet import Prophet\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "import utils\n",
    "from LinearAlignment import LinearAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWYkckHCJE6l"
   },
   "outputs": [],
   "source": [
    "def smape(satellite_predicted_values, satellite_true_values):\n",
    "    # the division, addition and subtraction are pointwise\n",
    "\n",
    "    return np.mean(np.abs((satellite_predicted_values - satellite_true_values)/\n",
    "                (np.abs(satellite_predicted_values) + np.abs(satellite_true_values))))\n",
    "\n",
    "\n",
    "def drop_close(t, x, eps=10**9):\n",
    "    '''\n",
    "    t = time array, x = data array, eps is in nanoseconds\n",
    "    Returns entries in t,x with corresponding consecutive times > eps\n",
    "    \n",
    "    '''\n",
    "    t = np.array(t) #if not already np array, convert\n",
    "    x = np.array(x) #if t or x are pandas Series, will have dimension mismatch\n",
    "    far = np.concatenate([(t[1:] - t[:-1]) > eps, [True]])\n",
    "    return t[far], x[far]\n",
    "\n",
    "\n",
    "def resample(t, x, step=10 * 10**9, t_new=None, return_t=False):\n",
    "    '''\n",
    "    t: time array (or series); \n",
    "    x: data array (or series); \n",
    "    t_new: new time scale from start to end of t with step size step;\n",
    "    step: = 10 seconds by default; \n",
    "    return_t: by default, do not return resampled times\n",
    "    \n",
    "    resample time series or array by 10 (default) sec intervals and \n",
    "    return new time series (if t_new=True) and spline approximation series for data\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    t, x = drop_close(t, x)\n",
    "    if t_new is None:\n",
    "        t_new = np.arange(t[0], t[-1], step)\n",
    "    try:\n",
    "        spl = splrep(t, x)\n",
    "        x_new = splev(t_new, spl)\n",
    "    except:\n",
    "        raise ValueError(f'interpolation error, x length = {len(x)}, \\\n",
    "        t_new length = {len(t_new)}')\n",
    "\n",
    "    return (t_new, x_new) if return_t else x_new\n",
    "\n",
    "\n",
    "def get_peaks(array):\n",
    "    '''\n",
    "    returns index of \"sharp\" peaks, excluding first and last values of array\n",
    "    \n",
    "    index of \"smooth peaks\", e.g. 1 2 3 9 9 3 2 1, is not returned\n",
    "    '''\n",
    "    return np.where((array[1:-1] > array[2:]) & (array[1:-1] > array[:-2]))[0] + 1\n",
    "\n",
    "\n",
    "def get_satellite_data(data, sat_id):\n",
    "    '''\n",
    "    returns all data for particular satellite by id\n",
    "    '''\n",
    "    return data[data['sat_id'] == sat_id]\n",
    "\n",
    "\n",
    "def remove_time_jumps(satellite_data, features_list=('x_sim', 'y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim'),\n",
    "                      suffix='_jumps_removed',time_threshold = 0.00003):\n",
    "    #time_threshold 0.00003 sufficient for test and train\n",
    "    #time_threshold 0.00002 will throw errors\n",
    "    '''\n",
    "    removes time jumps in the simulation for a single satellite\n",
    "    for train and test data, sufficient to set time_threshold at default\n",
    "    '''\n",
    "    satellite_data['t'] = ((pd.to_datetime(satellite_data['epoch']) - pd.to_datetime(satellite_data['epoch'])[0]) /\n",
    "                           np.timedelta64(1, 'D')).astype(float)\n",
    "    satellite_data['dt'] = satellite_data['t'].diff()\n",
    "    # the most frequent time interval\n",
    "    t_standard = satellite_data['dt'].value_counts().index[0]\n",
    "\n",
    "    # time steps used for simulations\n",
    "    satellite_data['t_sim'] = satellite_data.index.values * t_standard\n",
    "\n",
    "    n = satellite_data.shape[0]\n",
    "    corrected_features = []\n",
    "    for feature_name in features_list:\n",
    "        corrected_feature = [0] * n\n",
    "        corrected_feature[0] = satellite_data[feature_name][0]\n",
    "\n",
    "        feature = satellite_data[feature_name]\n",
    "\n",
    "        for j in range(1, n - 1):\n",
    "            if satellite_data.t[j] < satellite_data.t_sim[j] - time_threshold:\n",
    "                # approximate by the left side\n",
    "    \n",
    "                # look for the interval\n",
    "                step = 0\n",
    "                while satellite_data.t[j] < satellite_data.t_sim[j - step] - time_threshold:\n",
    "                    step += 1\n",
    "                #             print(step)\n",
    "                corrected_feature[j] = feature[j - step] - (satellite_data.t_sim[j - step] - satellite_data.t[j]) / (\n",
    "                            satellite_data.t_sim[j - step] - satellite_data.t_sim[j - step - 1]) * (\n",
    "                                              feature[j - step] - feature[j - step - 1])\n",
    "            elif satellite_data.t[j] > satellite_data.t_sim[j] + time_threshold:\n",
    "                # approximate by the right side\n",
    "    \n",
    "                # look for the interval\n",
    "                step = 0\n",
    "                while satellite_data.t[j] > satellite_data.t_sim[j + step] + time_threshold:\n",
    "                    step += 1\n",
    "    \n",
    "                corrected_feature[j] = feature[j + step + 1] - (satellite_data.t_sim[j + step + 1] - satellite_data.t[j]) / (\n",
    "                            satellite_data.t_sim[j + step + 1] - satellite_data.t_sim[j + step]) * (\n",
    "                                              feature[j + step + 1] - feature[j + step])\n",
    "            else:\n",
    "                corrected_feature[j] = feature[j]\n",
    "    \n",
    "        corrected_feature[n - 1] = feature[n - 1] + corrected_feature[n - 2] - feature[n - 2]\n",
    "        corrected_features.append(corrected_feature)\n",
    "    return pd.DataFrame(corrected_features, index=[f + suffix for f in features_list]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TN9lNVPJE6s"
   },
   "outputs": [],
   "source": [
    "def insert_previous_and_shift(df,col_name,ind):\n",
    "    '''\n",
    "    input a data frame (df), column name (col_name), and index (ind)\n",
    "    insert previous value of df[col_name] at index and shift the rest \n",
    "    of df[col_name] from ind by +1;\n",
    "    This is used for remove_time_jumps_fast\n",
    "    '''\n",
    "    shifted_series = df[col_name].shift(1)\n",
    "    df[col_name].iloc[ind] = df[col_name].iloc[ind-1]\n",
    "    df[col_name].iloc[ind+1:] = shifted_series.iloc[ind+1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilY6WzcOJE60"
   },
   "outputs": [],
   "source": [
    "def remove_time_jumps_fast(data, features_list=\n",
    "                           ('x_sim', 'y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim'),\n",
    "                           threshold = 0.000001):\n",
    "    #time_threshold 0.00003 sufficient for test and train\n",
    "    #time_threshold 0.00002 will throw errors\n",
    "    '''\n",
    "    removes time jumps in the simulation for a single satellite\n",
    "    for train and test data, sufficient to set time_threshold at default\n",
    "    s_data = satellite data\n",
    "    the features are replaced by the correction\n",
    "    note that threshold here is not the same as in remove_time_jumps\n",
    "    '''\n",
    "    epoch_ind = data.columns.get_loc('epoch')\n",
    "    data['t'] = ((pd.to_datetime(data['epoch']) - pd.to_datetime(data.iloc[0,epoch_ind])) /\n",
    "                               np.timedelta64(1, 'D')).astype(float)\n",
    "    data['dt'] = data['t'].diff(1)\n",
    "\n",
    "    index_for_correction = data[data['dt'] < threshold].index \n",
    "    #print(index_for_correction)\n",
    "    if list(index_for_correction): #if non empty\n",
    "        for feature in features_list:\n",
    "            for i in index_for_correction:\n",
    "                j = data.index.get_loc(i)\n",
    "                data = insert_previous_and_shift(data,feature,j)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_simulated_feats(data, stretch,true_feats = 'position',\n",
    "                           suffix=\"_stretch\"):\n",
    "    '''\n",
    "    stretch time scale for simulation to better match true data,\n",
    "    for a single sattelite;\n",
    "    use predetermined stretch coefficient (depends on the satellite)\n",
    "    \n",
    "    '''\n",
    "    if true_feats == 'position':\n",
    "        true_feats_list = ['x','y','z']\n",
    "    elif true_feats == 'velocity':\n",
    "        true_feats_list = ['Vx','Vy','Vz']\n",
    "    elif true_feats == 'all':\n",
    "        true_feats_list = ['x','y','z'] + ['Vx','Vy','Vz']\n",
    "    else:\n",
    "        true_feats_list = true_feats\n",
    "    \n",
    "    for feature in true_feats_list:\n",
    "        spl = splrep(stretch*data['t'],data[feature+'_sim'])\n",
    "        test_stretch = splev(data['t'], spl) #np array\n",
    "        data[feature+suffix] = test_stretch\n",
    "    \n",
    "    return data\n",
    "\n",
    "def amp_sim_feats(data, amp_stretch,feats = ['Vx_sim','Vy_sim','Vz_sim'],\n",
    "                           suffix=\"_stretch_amp\"):\n",
    "    '''\n",
    "    vary amplitude for simulation to better match true data,\n",
    "    for a single sattelite;\n",
    "    use predetermined amp_stretch coefficient (depends on the satellite)\n",
    "    \n",
    "    '''\n",
    "    if feats == 'position':\n",
    "        feats_list = ['x_sim','y_sim','z_sim']\n",
    "    elif feats == 'velocity':\n",
    "        feats_list = ['Vx_sim','Vy_sim','Vz_sim']\n",
    "    elif feats == 'all':\n",
    "        feats_list = ['x_sim','y_sim','z_sim'] + ['Vx_sim','Vy_sim','Vz_sim']\n",
    "    else:\n",
    "        feats_list = feats\n",
    "        \n",
    "    for feature in feats_list:\n",
    "        data[feature+suffix] = amp_stretch*data[feature]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hMW8narvJE67"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "iFtkEKxZJE7O",
    "outputId": "670fafeb-efc8-4614-c723-d96bdeae1c5d"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv', index_col = 'id')\n",
    "data['time'] = data['epoch']\n",
    "data['epoch'] = pd.to_datetime(data['epoch']).values.astype(float)\n",
    "data['epoch'] = data['epoch'] - data['epoch'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('data/test.csv', index_col = 'id')\n",
    "test_data['time'] = test_data['epoch']\n",
    "test_data['epoch'] = pd.to_datetime(test_data['epoch']).values.astype(float)\n",
    "test_data['epoch'] = test_data['epoch'] - data['epoch'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track 1 train data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_t1 = test_data['sat_id'].unique()\n",
    "data = data[data['sat_id'].isin(sat_t1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([data,test_data],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = data.index\n",
    "test_index = test_data.index\n",
    "all_index = all_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = ['x','y','z','Vx','Vy','Vz']\n",
    "feature_list = [t+'_sim' for t in target_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove time jumps: track 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove_time_jumps_fast on all track1 satellites only, compute smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:35<00:00,  8.54it/s]\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "remove_jumps = pd.DataFrame([])\n",
    "for sat_id in tqdm(sat_t1):\n",
    "    sat_data = get_satellite_data(all_data, sat_id)\n",
    "    sat_data = remove_time_jumps_fast(sat_data)\n",
    "    remove_jumps = remove_jumps.append(sat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_jumps_train = remove_jumps.drop('dt',axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_jumps_test = remove_jumps.loc[~remove_jumps.index.isin(remove_jumps.drop('dt',axis=1).dropna().index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_train.index.equals(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_test.index.equals(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_remove_jumps = []\n",
    "for sat in sat_t1:\n",
    "    d = get_satellite_data(remove_jumps_train,sat)\n",
    "    smape_remove_jumps.append(smape(d[feature_list].to_numpy(),d[target_list].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add linear alignment\n",
    "after having removed time jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "McB3F4RvJE7U",
    "outputId": "c435e3f6-bb60-49e6-cbf5-c517076b1c32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:37<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "alignment_model = LinearAlignment()\n",
    "transf_df = pd.DataFrame([])\n",
    "for sat_id in tqdm(sat_t1):\n",
    "    try:\n",
    "        sat_data = get_satellite_data(remove_jumps, sat_id)\n",
    "        n_first = sat_data.shape[0] - sat_data['x'].isnull().sum()\n",
    "        index = sat_data.index\n",
    "        pred = pd.DataFrame(index = index)\n",
    "        sat_data.set_index(index)\n",
    "    except KeyError as e:\n",
    "        print(f'jump removal failed for satellite {sat_id}:\\t{type(e).__name__} {e}')\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    n_train = 4*len(sat_data) // 10\n",
    "    train_sat_data = sat_data[:n_train]\n",
    "    \n",
    "    pred['epoch'] = sat_data['epoch'].values\n",
    "    pred['t'] = sat_data['t'].values\n",
    "    pred['sat_id'] = sat_id\n",
    "    \n",
    "    try:\n",
    "        for feature_name in target_list:\n",
    "            alignment_model.fit(t=train_sat_data['epoch'].values,\n",
    "                                x=-train_sat_data[f'{feature_name}_sim'].values,\n",
    "                                gt=-train_sat_data[feature_name].values)\n",
    "            option1 = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "            alignment_model.fit(t=train_sat_data['epoch'].values,\n",
    "                                x= train_sat_data[f'{feature_name}_sim'].values,\n",
    "                                gt= train_sat_data[feature_name].values)\n",
    "\n",
    "            option2 = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "\n",
    "            if utils.smape(option1[n_train:n_first],sat_data[feature_name].values[n_train:n_first]) < utils.smape(option2[n_train:n_first],sat_data[feature_name].values[n_train:n_first]):\n",
    "                alignment_model.fit(t=sat_data['epoch'].iloc[:n_first].values,\n",
    "                                x=-sat_data[f'{feature_name}_sim'].iloc[:n_first].values,\n",
    "                                gt=-sat_data[feature_name].iloc[:n_first].values)\n",
    "\n",
    "                pred[f'{feature_name}_sim'] = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "            else:\n",
    "                alignment_model.fit(t=sat_data['epoch'].iloc[:n_first].values,\n",
    "                                x=sat_data[f'{feature_name}_sim'].iloc[:n_first].values,\n",
    "                                gt=sat_data[feature_name].iloc[:n_first].values)\n",
    "                pred[f'{feature_name}_sim']  = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "\n",
    "            pred.loc[:,feature_name]=sat_data.loc[:, feature_name].values\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'linear alignment failed for satellite {sat_id}:\\t{type(e).__name__} {e}')\n",
    "        continue\n",
    "    transf_df = transf_df.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_jumps_la = transf_df.copy()\n",
    "remove_jumps_la_train = remove_jumps_la.dropna()\n",
    "remove_jumps_la_test = remove_jumps_la.loc[~remove_jumps_la.index.isin\n",
    "                                           (remove_jumps_la.dropna().index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_la_train.index.equals(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_la_test.index.equals(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_remove_jumps_la = []\n",
    "for sat in sat_t1:\n",
    "    d = get_satellite_data(remove_jumps_la_train,sat)\n",
    "    smape_remove_jumps_la.append(smape(d[feature_list].to_numpy(),d[target_list].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check tails for all satellites, to be sure LA did not remove any data at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check tail on 372,587,523,473,515\n",
    "import random\n",
    "threshold = 0.0001\n",
    "for i in sat_t1:\n",
    "    if abs(get_satellite_data(remove_jumps_la,i)['Vx_sim'].tail(10).mean()) < threshold:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch horizontally\n",
    "\n",
    "Will find one coefficient for x,y,z and another for Vx,Vy,Vz; that is best in terms of smape on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_feats = ['Vx','Vy','Vz']\n",
    "sim_feats = [f + '_sim' for f in true_feats]\n",
    "stretched_feats = [f+'_stretch' for f in true_feats]\n",
    "stretch_amp_feats = [f + '_amp' for f in stretched_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretch_dict_vel = {}\n",
    "for sat in tqdm(sat_t1):\n",
    "    d = get_satellite_data(remove_jumps_train, sat)\n",
    "    \n",
    "    stretch_list = []\n",
    "    for i in np.arange(0.98,1.02,0.005):\n",
    "        d = stretch_simulated_feats(d,i,true_feats='velocity',suffix='_stretch')\n",
    "        metric = smape(d[true_feats].to_numpy(),d[stretched_feats].to_numpy())\n",
    "        stretch_list.append((i,metric))\n",
    "        #print('i:',i)\n",
    "        #print('smape:',metric)\n",
    "    best = min(stretch_list, key = lambda t: t[1])\n",
    "    stretch_dict_vel[sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_stretch = [k for k,v in stretch_dict_vel.items() if (v <= 0.98 or v >= 1.02)]\n",
    "extreme_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sat in extreme_stretch:\n",
    "    d = get_satellite_data(remove_jumps_train, sat)\n",
    "    \n",
    "    stretch_list = []\n",
    "    for i in np.arange(0.94,1.06,0.005):\n",
    "        d = stretch_simulated_feats(d,i,true_feats = 'velocity')\n",
    "        metric = smape(d[true_feats].to_numpy(),d[stretched_feats].to_numpy())\n",
    "        stretch_list.append((i,metric))\n",
    "        #print('i:',i)\n",
    "        #print('smape:',metric)\n",
    "    best = min(stretch_list, key = lambda t: t[1])\n",
    "    stretch_dict_vel[sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_stretch = [k for k,v in stretch_dict_vel.items() if (v <= 0.94 or v >= 1.06)]\n",
    "extreme_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stretch_dict_vel = {int(k):v for k,v in stretch_dict_vel.items()}\n",
    "\n",
    "#save stretch_dict\n",
    "import json\n",
    "#with open('stretch_dict_vel.txt', 'w') as file:\n",
    "#    json.dump(stretch_dict_vel, file)\n",
    "\n",
    "with open('stretch_dict_vel.txt', 'r') as file:\n",
    "    stretch_dict_vel = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#position\n",
    "true_feats = ['x','y','z']\n",
    "sim_feats = [f + '_sim' for f in true_feats]\n",
    "stretched_feats = [f+'_stretch' for f in true_feats]\n",
    "stretch_amp_feats = [f + '_amp' for f in stretched_feats]\n",
    "stretch_dict_pos = {}\n",
    "for sat in tqdm(sat_t1):\n",
    "    d = get_satellite_data(remove_jumps_train, sat)\n",
    "    \n",
    "    stretch_list = []\n",
    "    for i in np.arange(0.98,1.02,0.005):\n",
    "        d = stretch_simulated_feats(d,i,true_feats='position',suffix='_stretch')\n",
    "        metric = smape(d[true_feats].to_numpy(),d[stretched_feats].to_numpy())\n",
    "        stretch_list.append((i,metric))\n",
    "        #print('i:',i)\n",
    "        #print('smape:',metric)\n",
    "    best = min(stretch_list, key = lambda t: t[1])\n",
    "    stretch_dict_pos[sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_stretch = [k for k,v in stretch_dict_pos.items() if (v <= 0.98 or v >= 1.02)]\n",
    "extreme_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sat in extreme_stretch:\n",
    "    d = get_satellite_data(remove_jumps_train, sat)\n",
    "    \n",
    "    stretch_list = []\n",
    "    for i in np.arange(0.9,1.1,0.005):\n",
    "        d = stretch_simulated_feats(d,i,true_feats = 'position')\n",
    "        metric = smape(d[true_feats].to_numpy(),d[stretched_feats].to_numpy())\n",
    "        stretch_list.append((i,metric))\n",
    "        #print('i:',i)\n",
    "        #print('smape:',metric)\n",
    "    best = min(stretch_list, key = lambda t: t[1])\n",
    "    stretch_dict_pos[sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_stretch = [k for k,v in stretch_dict_pos.items() if (v <= 0.9 or v >= 1.1)]\n",
    "extreme_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stretch_dict_pos = {int(k):v for k,v in stretch_dict_pos.items()}\n",
    "#save stretch_dict\n",
    "import json\n",
    "#with open('stretch_dict_pos.txt', 'w') as file:\n",
    "#    json.dump(stretch_dict_pos, file)\n",
    "\n",
    "with open('stretch_dict_pos.txt', 'r') as file:\n",
    "    stretch_dict_pos = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal stretch after LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_feats = ['Vx','Vy','Vz']\n",
    "sim_feats = [f + '_sim' for f in true_feats]\n",
    "stretched_feats = [f+'_stretch' for f in true_feats]\n",
    "stretch_amp_feats = [f + '_amp' for f in stretched_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretch_dict_la_vel = {}\n",
    "for sat in tqdm(sat_t1):\n",
    "    d = get_satellite_data(remove_jumps_la_train, sat)\n",
    "    \n",
    "    stretch_list = []\n",
    "    for i in np.arange(0.95,1.05,0.005):\n",
    "        d = stretch_simulated_feats(d,i,true_feats='velocity',suffix='_stretch')\n",
    "        metric = smape(d[true_feats].to_numpy(),d[stretched_feats].to_numpy())\n",
    "        stretch_list.append((i,metric))\n",
    "        #print('i:',i)\n",
    "        #print('smape:',metric)\n",
    "    best = min(stretch_list, key = lambda t: t[1])\n",
    "    stretch_dict_la_vel[sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_stretch = [k for k,v in stretch_dict_la_vel.items() if (v <= 0.95 or v >= 1.05)]\n",
    "extreme_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stretch_dict_la_vel = {int(k):v for k,v in stretch_dict_la_vel.items()}\n",
    "#save stretch_dict\n",
    "import json\n",
    "#with open('stretch_dict_la_vel.txt', 'w') as file:\n",
    "#    json.dump(stretch_dict_la_vel, file)\n",
    "\n",
    "with open('stretch_dict_la_vel.txt', 'r') as file:\n",
    "    stretch_dict_la_vel = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#position\n",
    "true_feats = ['x','y','z']\n",
    "sim_feats = [f + '_sim' for f in true_feats]\n",
    "stretched_feats = [f+'_stretch' for f in true_feats]\n",
    "stretch_amp_feats = [f + '_amp' for f in stretched_feats]\n",
    "stretch_dict_la_pos = {}\n",
    "for sat in tqdm(sat_t1):\n",
    "    d = get_satellite_data(remove_jumps_la_train, sat)\n",
    "    \n",
    "    stretch_list = []\n",
    "    for i in np.arange(0.96,1.04,0.005):\n",
    "        d = stretch_simulated_feats(d,i,true_feats='position',suffix='_stretch')\n",
    "        metric = smape(d[true_feats].to_numpy(),d[stretched_feats].to_numpy())\n",
    "        stretch_list.append((i,metric))\n",
    "        #print('i:',i)\n",
    "        #print('smape:',metric)\n",
    "    best = min(stretch_list, key = lambda t: t[1])\n",
    "    stretch_dict_la_pos[sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_stretch = [k for k,v in stretch_dict_la_pos.items() if (v <= 0.96 or v >= 1.04)]\n",
    "extreme_stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stretch_dict_la_pos = {int(k):v for k,v in stretch_dict_la_pos.items()}\n",
    "#save stretch_dict\n",
    "import json\n",
    "#with open('stretch_dict_la_pos.txt', 'w') as file:\n",
    "#    json.dump(stretch_dict_la_pos, file)\n",
    "\n",
    "with open('stretch_dict_la_pos.txt', 'r') as file:\n",
    "    stretch_dict_la_pos = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch amplitude, individually for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_dict_pos = {}\n",
    "for dim in ['x','y','z']:\n",
    "    amp_dict_pos[dim] = {}\n",
    "    for sat in tqdm(sat_t1):\n",
    "        amplitude_list = []\n",
    "        for i in np.arange(0.9,1.1,0.01):\n",
    "            d = get_satellite_data(remove_jumps_train,sat)\n",
    "            d = stretch_simulated_feats(d,stretch_dict_pos[str(sat)],true_feats = 'position',suffix='')\n",
    "            d = amp_sim_feats(d,i,feats = 'position',suffix='')\n",
    "            metric = smape(d['{}'.format(dim)].to_numpy(),d['{}_sim'.format(dim)].to_numpy())\n",
    "            amplitude_list.append((i,metric))\n",
    "            #print('i:',i)\n",
    "            #print('smape:',metric)\n",
    "        best = min(amplitude_list, key = lambda t: t[1])\n",
    "        amp_dict_pos[dim][sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_amp = {}\n",
    "for dim in ['x','y','z']:\n",
    "    extreme_amp[dim] = [k for k,v in amp_dict_pos[dim].items() if (v <= 0.9 or v >= 1.1)]\n",
    "extreme_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in ['x','y','z']:\n",
    "    for sat in extreme_amp[dim]:\n",
    "        amplitude_list = []\n",
    "        for i in np.arange(0.1,1.9,0.01):\n",
    "            d = get_satellite_data(remove_jumps_train,sat)\n",
    "            d = stretch_simulated_feats(d,stretch_dict_pos[str(sat)],true_feats = 'position',suffix='')\n",
    "            d = amp_sim_feats(d,i,feats = 'position',suffix='')\n",
    "            metric = smape(d['{}'.format(dim)].to_numpy(),d['{}_sim'.format(dim)].to_numpy())\n",
    "            amplitude_list.append((i,metric))\n",
    "            #print('i:',i)\n",
    "            #print('smape:',metric)\n",
    "        best = min(amplitude_list, key = lambda t: t[1])\n",
    "        amp_dict_pos[dim][sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_amp = {}\n",
    "for dim in ['x','y','z']:\n",
    "    extreme_amp[dim] = [k for k,v in amp_dict_pos[dim].items() if (v <= 0.1 or v >= 1.9)]\n",
    "extreme_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dim in ['x','y','z']:\n",
    "#    amp_dict_pos[dim] = {int(k):v for k,v in amp_dict_pos[dim].items()}\n",
    "#save stretch_dict\n",
    "import json\n",
    "#with open('amp_dict_pos.txt', 'w') as file:\n",
    "#    json.dump(amp_dict_pos, file)\n",
    "\n",
    "with open('amp_dict_pos.txt', 'r') as file:\n",
    "    amp_dict_pos = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_dict_vel = {}\n",
    "for dim in ['Vx','Vy','Vz']:\n",
    "    amp_dict_vel[dim] = {}\n",
    "    for sat in tqdm(sat_t1):\n",
    "        amplitude_list = []\n",
    "        for i in np.arange(0.9,1.1,0.01):\n",
    "            d = get_satellite_data(remove_jumps_train,sat)\n",
    "            d = stretch_simulated_feats(d,stretch_dict_vel[str(sat)],true_feats = 'velocity',suffix='')\n",
    "            d = amp_sim_feats(d,i,feats = 'velocity',suffix='')\n",
    "            metric = smape(d['{}'.format(dim)].to_numpy(),d['{}_sim'.format(dim)].to_numpy())\n",
    "            amplitude_list.append((i,metric))\n",
    "        best = min(amplitude_list, key = lambda t: t[1])\n",
    "        amp_dict_vel[dim][sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_amp = {}\n",
    "for dim in ['Vx','Vy','Vz']:\n",
    "    extreme_amp[dim] = [k for k,v in amp_dict_vel[dim].items() if (v <= 0.9 or v >= 1.1)]\n",
    "extreme_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in ['Vx','Vy','Vz']:\n",
    "    for sat in extreme_amp[dim]:\n",
    "        amplitude_list = []\n",
    "        for i in np.arange(0.1,1.9,0.01):\n",
    "            d = get_satellite_data(remove_jumps_train,sat)\n",
    "            d = stretch_simulated_feats(d,stretch_dict_vel[str(sat)],true_feats = 'velocity',suffix='')\n",
    "            d = amp_sim_feats(d,i,feats = 'velocity',suffix='')\n",
    "            metric = smape(d['{}'.format(dim)].to_numpy(),d['{}_sim'.format(dim)].to_numpy())\n",
    "            amplitude_list.append((i,metric))\n",
    "            #print('i:',i)\n",
    "            #print('smape:',metric)\n",
    "        best = min(amplitude_list, key = lambda t: t[1])\n",
    "        amp_dict_vel[dim][sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_amp = {}\n",
    "for dim in ['Vx','Vy','Vz']:\n",
    "    extreme_amp[dim] = [k for k,v in amp_dict_vel[dim].items() if (v <= 0.1 or v >= 1.9)]\n",
    "extreme_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dim in ['Vx','Vy','Vz']:\n",
    "#    amp_dict_vel[dim] = {int(k):v for k,v in amp_dict_vel[dim].items()}\n",
    "#save stretch_dict\n",
    "#import json\n",
    "#with open('amp_dict_vel.txt', 'w') as file:\n",
    "#    json.dump(amp_dict_vel, file)\n",
    "\n",
    "with open('amp_dict_vel.txt', 'r') as file:\n",
    "    amp_dict_vel = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amplitude stretch after LA and horizontal stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_dict_la_pos = {}\n",
    "for dim in ['x','y','z']:\n",
    "    amp_dict_la_pos[dim] = {}\n",
    "    for sat in tqdm(sat_t1):\n",
    "        amplitude_list = []\n",
    "        for i in np.arange(0.9,1.1,0.01):\n",
    "            d = get_satellite_data(remove_jumps_la_train,sat)\n",
    "            d = stretch_simulated_feats(d,stretch_dict_la_pos[str(sat)],true_feats = 'position',suffix='')\n",
    "            d = amp_sim_feats(d,i,feats = 'position',suffix='')\n",
    "            metric = smape(d['{}'.format(dim)].to_numpy(),d['{}_sim'.format(dim)].to_numpy())\n",
    "            amplitude_list.append((i,metric))\n",
    "            #print('i:',i)\n",
    "            #print('smape:',metric)\n",
    "        best = min(amplitude_list, key = lambda t: t[1])\n",
    "        amp_dict_la_pos[dim][sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_amp = {}\n",
    "for dim in ['x','y','z']:\n",
    "    extreme_amp[dim] = [k for k,v in amp_dict_la_pos[dim].items() if (v <= 0.9 or v >= 1.1)]\n",
    "extreme_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dim in ['x','y','z']:\n",
    "#    amp_dict_la_pos[dim] = {int(k):v for k,v in amp_dict_la_pos[dim].items()}\n",
    "#save stretch_dict\n",
    "#import json\n",
    "#with open('amp_dict_la_pos.txt', 'w') as file:\n",
    "#    json.dump(amp_dict_la_pos, file)\n",
    "\n",
    "with open('amp_dict_la_pos.txt', 'r') as file:\n",
    "    amp_dict_la_pos = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_dict_la_vel = {}\n",
    "for dim in ['Vx','Vy','Vz']:\n",
    "    amp_dict_la_vel[dim] = {}\n",
    "    for sat in tqdm(sat_t1):\n",
    "        amplitude_list = []\n",
    "        for i in np.arange(0.9,1.1,0.01):\n",
    "            d = get_satellite_data(remove_jumps_la_train,sat)\n",
    "            d = stretch_simulated_feats(d,stretch_dict_la_vel[str(sat)],true_feats = 'velocity',suffix='')\n",
    "            d = amp_sim_feats(d,i,feats = 'velocity',suffix='')\n",
    "            metric = smape(d['{}'.format(dim)].to_numpy(),d['{}_sim'.format(dim)].to_numpy())\n",
    "            amplitude_list.append((i,metric))\n",
    "        best = min(amplitude_list, key = lambda t: t[1])\n",
    "        amp_dict_la_vel[dim][sat] = best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_amp = {}\n",
    "for dim in ['Vx','Vy','Vz']:\n",
    "    extreme_amp[dim] = [k for k,v in amp_dict_la_vel[dim].items() if (v <= 0.1 or v >= 1.9)]\n",
    "extreme_amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dim in ['Vx','Vy','Vz']:\n",
    "#    amp_dict_la_vel[dim] = {int(k):v for k,v in amp_dict_la_vel[dim].items()}\n",
    "#save stretch_dict\n",
    "#import json\n",
    "#with open('amp_dict_la_vel.txt', 'w') as file:\n",
    "#    json.dump(amp_dict_la_vel, file)\n",
    "\n",
    "with open('amp_dict_la_vel.txt', 'r') as file:\n",
    "    amp_dict_la_vel = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply stretching to data\n",
    "\n",
    "\n",
    "1. To `remove_jumps` df\n",
    "\n",
    "2. Next, to `remove_jumps_la` df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [get_satellite_data(remove_jumps,i) for i in sat_t1]\n",
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>sat_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "      <th>x_sim</th>\n",
       "      <th>y_sim</th>\n",
       "      <th>z_sim</th>\n",
       "      <th>Vx_sim</th>\n",
       "      <th>Vy_sim</th>\n",
       "      <th>Vz_sim</th>\n",
       "      <th>time</th>\n",
       "      <th>t</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1231060</th>\n",
       "      <td>1.393565e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77054.582572</td>\n",
       "      <td>-59078.354514</td>\n",
       "      <td>-568.800871</td>\n",
       "      <td>-0.803702</td>\n",
       "      <td>-1.297028</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>2014-02-28T05:19:01.386</td>\n",
       "      <td>16129.221544</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231061</th>\n",
       "      <td>1.393572e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70256.332335</td>\n",
       "      <td>-67906.739391</td>\n",
       "      <td>638.268409</td>\n",
       "      <td>-1.037560</td>\n",
       "      <td>-1.095490</td>\n",
       "      <td>0.163476</td>\n",
       "      <td>2014-02-28T07:21:46.454</td>\n",
       "      <td>16129.306788</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231062</th>\n",
       "      <td>1.393579e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61829.238915</td>\n",
       "      <td>-75160.476673</td>\n",
       "      <td>1830.266511</td>\n",
       "      <td>-1.246389</td>\n",
       "      <td>-0.869204</td>\n",
       "      <td>0.159549</td>\n",
       "      <td>2014-02-28T09:24:31.522</td>\n",
       "      <td>16129.392032</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231063</th>\n",
       "      <td>1.393587e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51953.463644</td>\n",
       "      <td>-80650.378576</td>\n",
       "      <td>2978.927754</td>\n",
       "      <td>-1.431064</td>\n",
       "      <td>-0.616020</td>\n",
       "      <td>0.151705</td>\n",
       "      <td>2014-02-28T11:27:16.590</td>\n",
       "      <td>16129.477275</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231064</th>\n",
       "      <td>1.393594e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40809.611234</td>\n",
       "      <td>-84165.238391</td>\n",
       "      <td>4054.152281</td>\n",
       "      <td>-1.590525</td>\n",
       "      <td>-0.332080</td>\n",
       "      <td>0.139551</td>\n",
       "      <td>2014-02-28T13:30:01.658</td>\n",
       "      <td>16129.562519</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                epoch  sat_id   x   y   z  Vx  Vy  Vz         x_sim  \\\n",
       "id                                                                    \n",
       "1231060  1.393565e+18     597 NaN NaN NaN NaN NaN NaN  77054.582572   \n",
       "1231061  1.393572e+18     597 NaN NaN NaN NaN NaN NaN  70256.332335   \n",
       "1231062  1.393579e+18     597 NaN NaN NaN NaN NaN NaN  61829.238915   \n",
       "1231063  1.393587e+18     597 NaN NaN NaN NaN NaN NaN  51953.463644   \n",
       "1231064  1.393594e+18     597 NaN NaN NaN NaN NaN NaN  40809.611234   \n",
       "\n",
       "                y_sim        z_sim    Vx_sim    Vy_sim    Vz_sim  \\\n",
       "id                                                                 \n",
       "1231060 -59078.354514  -568.800871 -0.803702 -1.297028  0.163600   \n",
       "1231061 -67906.739391   638.268409 -1.037560 -1.095490  0.163476   \n",
       "1231062 -75160.476673  1830.266511 -1.246389 -0.869204  0.159549   \n",
       "1231063 -80650.378576  2978.927754 -1.431064 -0.616020  0.151705   \n",
       "1231064 -84165.238391  4054.152281 -1.590525 -0.332080  0.139551   \n",
       "\n",
       "                            time             t        dt  \n",
       "id                                                        \n",
       "1231060  2014-02-28T05:19:01.386  16129.221544  0.085244  \n",
       "1231061  2014-02-28T07:21:46.454  16129.306788  0.085244  \n",
       "1231062  2014-02-28T09:24:31.522  16129.392032  0.085244  \n",
       "1231063  2014-02-28T11:27:16.590  16129.477275  0.085244  \n",
       "1231064  2014-02-28T13:30:01.658  16129.562519  0.085244  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#horizontal stretch\n",
    "for df in df_list:\n",
    "    df = stretch_simulated_feats(df,stretch_dict_vel[str(int(df['sat_id'].unique()))],true_feats='velocity',suffix='_sim')\n",
    "    df = stretch_simulated_feats(df,stretch_dict_pos[str(int(df['sat_id'].unique()))],true_feats='position',suffix='_sim')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>sat_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "      <th>x_sim</th>\n",
       "      <th>y_sim</th>\n",
       "      <th>z_sim</th>\n",
       "      <th>Vx_sim</th>\n",
       "      <th>Vy_sim</th>\n",
       "      <th>Vz_sim</th>\n",
       "      <th>time</th>\n",
       "      <th>t</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1231060</th>\n",
       "      <td>1.393565e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77054.582572</td>\n",
       "      <td>-59078.354514</td>\n",
       "      <td>-568.800871</td>\n",
       "      <td>-0.803702</td>\n",
       "      <td>-1.297028</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>2014-02-28T05:19:01.386</td>\n",
       "      <td>16129.221544</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231061</th>\n",
       "      <td>1.393572e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70256.332335</td>\n",
       "      <td>-67906.739391</td>\n",
       "      <td>638.268409</td>\n",
       "      <td>-1.037560</td>\n",
       "      <td>-1.095490</td>\n",
       "      <td>0.163476</td>\n",
       "      <td>2014-02-28T07:21:46.454</td>\n",
       "      <td>16129.306788</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231062</th>\n",
       "      <td>1.393579e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61829.238915</td>\n",
       "      <td>-75160.476673</td>\n",
       "      <td>1830.266511</td>\n",
       "      <td>-1.246389</td>\n",
       "      <td>-0.869204</td>\n",
       "      <td>0.159549</td>\n",
       "      <td>2014-02-28T09:24:31.522</td>\n",
       "      <td>16129.392032</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231063</th>\n",
       "      <td>1.393587e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51953.463644</td>\n",
       "      <td>-80650.378576</td>\n",
       "      <td>2978.927754</td>\n",
       "      <td>-1.431064</td>\n",
       "      <td>-0.616020</td>\n",
       "      <td>0.151705</td>\n",
       "      <td>2014-02-28T11:27:16.590</td>\n",
       "      <td>16129.477275</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231064</th>\n",
       "      <td>1.393594e+18</td>\n",
       "      <td>597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40809.611234</td>\n",
       "      <td>-84165.238391</td>\n",
       "      <td>4054.152281</td>\n",
       "      <td>-1.590525</td>\n",
       "      <td>-0.332080</td>\n",
       "      <td>0.139551</td>\n",
       "      <td>2014-02-28T13:30:01.658</td>\n",
       "      <td>16129.562519</td>\n",
       "      <td>0.085244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                epoch  sat_id   x   y   z  Vx  Vy  Vz         x_sim  \\\n",
       "id                                                                    \n",
       "1231060  1.393565e+18     597 NaN NaN NaN NaN NaN NaN  77054.582572   \n",
       "1231061  1.393572e+18     597 NaN NaN NaN NaN NaN NaN  70256.332335   \n",
       "1231062  1.393579e+18     597 NaN NaN NaN NaN NaN NaN  61829.238915   \n",
       "1231063  1.393587e+18     597 NaN NaN NaN NaN NaN NaN  51953.463644   \n",
       "1231064  1.393594e+18     597 NaN NaN NaN NaN NaN NaN  40809.611234   \n",
       "\n",
       "                y_sim        z_sim    Vx_sim    Vy_sim    Vz_sim  \\\n",
       "id                                                                 \n",
       "1231060 -59078.354514  -568.800871 -0.803702 -1.297028  0.163600   \n",
       "1231061 -67906.739391   638.268409 -1.037560 -1.095490  0.163476   \n",
       "1231062 -75160.476673  1830.266511 -1.246389 -0.869204  0.159549   \n",
       "1231063 -80650.378576  2978.927754 -1.431064 -0.616020  0.151705   \n",
       "1231064 -84165.238391  4054.152281 -1.590525 -0.332080  0.139551   \n",
       "\n",
       "                            time             t        dt  \n",
       "id                                                        \n",
       "1231060  2014-02-28T05:19:01.386  16129.221544  0.085244  \n",
       "1231061  2014-02-28T07:21:46.454  16129.306788  0.085244  \n",
       "1231062  2014-02-28T09:24:31.522  16129.392032  0.085244  \n",
       "1231063  2014-02-28T11:27:16.590  16129.477275  0.085244  \n",
       "1231064  2014-02-28T13:30:01.658  16129.562519  0.085244  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#amplitude stretch\n",
    "for df in df_list:\n",
    "    for dim in ['Vx','Vy','Vz']:\n",
    "        #print(dim)\n",
    "        amp = amp_dict_vel[dim][str(int(df['sat_id'].unique()))]\n",
    "        #print(amp)\n",
    "        df['{}_sim'.format(dim)] = amp*df['{}_sim'.format(dim)]\n",
    "    for dim in ['x','y','z']:\n",
    "        amp = amp_dict_pos[dim][str(int(df['sat_id'].unique()))]\n",
    "        df['{}_sim'.format(dim)] = amp*df['{}_sim'.format(dim)]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_jumps_stretch = pd.concat(df_list,axis=0,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_jumps_stretch_train = remove_jumps_stretch.drop('dt',axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_stretch_test = remove_jumps_stretch.loc[~remove_jumps_stretch.index.isin\n",
    "                                           (remove_jumps_stretch_train.dropna().index)]\n",
    "remove_jumps_stretch_train.index.equals(data.index)\n",
    "remove_jumps_stretch_test.index.equals(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_remove_jumps_stretch = []\n",
    "for sat in sat_t1:\n",
    "    d = get_satellite_data(remove_jumps_stretch_train,sat)\n",
    "    smape_remove_jumps_stretch.append(smape(d[feature_list].to_numpy(),d[target_list].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now LA and stretch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [get_satellite_data(remove_jumps_la,i) for i in sat_t1]\n",
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>t</th>\n",
       "      <th>sat_id</th>\n",
       "      <th>x_sim</th>\n",
       "      <th>x</th>\n",
       "      <th>y_sim</th>\n",
       "      <th>y</th>\n",
       "      <th>z_sim</th>\n",
       "      <th>z</th>\n",
       "      <th>Vx_sim</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy_sim</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz_sim</th>\n",
       "      <th>Vz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1231060</th>\n",
       "      <td>1.393565e+18</td>\n",
       "      <td>16129.221544</td>\n",
       "      <td>597</td>\n",
       "      <td>3258.566123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85222.214779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6865.804981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.564234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.389517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.782024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231061</th>\n",
       "      <td>1.393572e+18</td>\n",
       "      <td>16129.306788</td>\n",
       "      <td>597</td>\n",
       "      <td>-11090.238004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85157.067499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7198.456304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.701828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231062</th>\n",
       "      <td>1.393579e+18</td>\n",
       "      <td>16129.392032</td>\n",
       "      <td>597</td>\n",
       "      <td>-25822.162385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82556.771379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7284.971503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.811503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.251472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.063917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231063</th>\n",
       "      <td>1.393587e+18</td>\n",
       "      <td>16129.477275</td>\n",
       "      <td>597</td>\n",
       "      <td>-40755.890567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77204.898038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7094.771615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.891778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.758888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.222861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231064</th>\n",
       "      <td>1.393594e+18</td>\n",
       "      <td>16129.562519</td>\n",
       "      <td>597</td>\n",
       "      <td>-55710.106089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-68885.019097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6597.277675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.941169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.322894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.394404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                epoch             t  sat_id         x_sim   x         y_sim  \\\n",
       "id                                                                            \n",
       "1231060  1.393565e+18  16129.221544     597   3258.566123 NaN -85222.214779   \n",
       "1231061  1.393572e+18  16129.306788     597 -11090.238004 NaN -85157.067499   \n",
       "1231062  1.393579e+18  16129.392032     597 -25822.162385 NaN -82556.771379   \n",
       "1231063  1.393587e+18  16129.477275     597 -40755.890567 NaN -77204.898038   \n",
       "1231064  1.393594e+18  16129.562519     597 -55710.106089 NaN -68885.019097   \n",
       "\n",
       "          y        z_sim   z    Vx_sim  Vx    Vy_sim  Vy    Vz_sim  Vz  \n",
       "id                                                                      \n",
       "1231060 NaN  6865.804981 NaN -1.564234 NaN  0.389517 NaN -0.782024 NaN  \n",
       "1231061 NaN  7198.456304 NaN -1.701828 NaN  0.796423 NaN -0.917122 NaN  \n",
       "1231062 NaN  7284.971503 NaN -1.811503 NaN  1.251472 NaN -1.063917 NaN  \n",
       "1231063 NaN  7094.771615 NaN -1.891778 NaN  1.758888 NaN -1.222861 NaN  \n",
       "1231064 NaN  6597.277675 NaN -1.941169 NaN  2.322894 NaN -1.394404 NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#horizontal stretch\n",
    "for df in df_list:\n",
    "    df = stretch_simulated_feats(df,stretch_dict_la_vel[str(int(df['sat_id'].unique()))],true_feats='velocity',suffix='_sim')\n",
    "    df = stretch_simulated_feats(df,stretch_dict_la_pos[str(int(df['sat_id'].unique()))],true_feats='position',suffix='_sim')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amplitude stretch\n",
    "for df in df_list:\n",
    "    for dim in ['Vx','Vy','Vz']:\n",
    "        #print(dim)\n",
    "        amp = amp_dict_la_vel[dim][str(int(df['sat_id'].unique()))]\n",
    "        #print(amp)\n",
    "        df['{}_sim'.format(dim)] = amp*df['{}_sim'.format(dim)]\n",
    "    for dim in ['x','y','z']:\n",
    "        amp = amp_dict_la_pos[dim][str(int(df['sat_id'].unique()))]\n",
    "        df['{}_sim'.format(dim)] = amp*df['{}_sim'.format(dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>t</th>\n",
       "      <th>sat_id</th>\n",
       "      <th>x_sim</th>\n",
       "      <th>x</th>\n",
       "      <th>y_sim</th>\n",
       "      <th>y</th>\n",
       "      <th>z_sim</th>\n",
       "      <th>z</th>\n",
       "      <th>Vx_sim</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy_sim</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz_sim</th>\n",
       "      <th>Vz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1231060</th>\n",
       "      <td>1.393565e+18</td>\n",
       "      <td>16129.221544</td>\n",
       "      <td>597</td>\n",
       "      <td>3258.566123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85222.214779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6865.804981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.564234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.389517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.782024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231061</th>\n",
       "      <td>1.393572e+18</td>\n",
       "      <td>16129.306788</td>\n",
       "      <td>597</td>\n",
       "      <td>-11090.238004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85157.067499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7198.456304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.701828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231062</th>\n",
       "      <td>1.393579e+18</td>\n",
       "      <td>16129.392032</td>\n",
       "      <td>597</td>\n",
       "      <td>-25822.162385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82556.771379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7284.971503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.811503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.251472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.063917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231063</th>\n",
       "      <td>1.393587e+18</td>\n",
       "      <td>16129.477275</td>\n",
       "      <td>597</td>\n",
       "      <td>-40755.890567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77204.898038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7094.771615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.891778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.758888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.222861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231064</th>\n",
       "      <td>1.393594e+18</td>\n",
       "      <td>16129.562519</td>\n",
       "      <td>597</td>\n",
       "      <td>-55710.106089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-68885.019097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6597.277675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.941169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.322894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.394404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                epoch             t  sat_id         x_sim   x         y_sim  \\\n",
       "id                                                                            \n",
       "1231060  1.393565e+18  16129.221544     597   3258.566123 NaN -85222.214779   \n",
       "1231061  1.393572e+18  16129.306788     597 -11090.238004 NaN -85157.067499   \n",
       "1231062  1.393579e+18  16129.392032     597 -25822.162385 NaN -82556.771379   \n",
       "1231063  1.393587e+18  16129.477275     597 -40755.890567 NaN -77204.898038   \n",
       "1231064  1.393594e+18  16129.562519     597 -55710.106089 NaN -68885.019097   \n",
       "\n",
       "          y        z_sim   z    Vx_sim  Vx    Vy_sim  Vy    Vz_sim  Vz  \n",
       "id                                                                      \n",
       "1231060 NaN  6865.804981 NaN -1.564234 NaN  0.389517 NaN -0.782024 NaN  \n",
       "1231061 NaN  7198.456304 NaN -1.701828 NaN  0.796423 NaN -0.917122 NaN  \n",
       "1231062 NaN  7284.971503 NaN -1.811503 NaN  1.251472 NaN -1.063917 NaN  \n",
       "1231063 NaN  7094.771615 NaN -1.891778 NaN  1.758888 NaN -1.222861 NaN  \n",
       "1231064 NaN  6597.277675 NaN -1.941169 NaN  2.322894 NaN -1.394404 NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_jumps_la_stretch = pd.concat(df_list,axis=0,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_jumps_la_stretch_train = remove_jumps_la_stretch.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_la_stretch_test = remove_jumps_la_stretch.loc[~remove_jumps_la_stretch.index.isin\n",
    "                                           (remove_jumps_la_stretch_train.dropna().index)]\n",
    "remove_jumps_la_stretch_train.index.equals(data.index)\n",
    "remove_jumps_la_stretch_test.index.equals(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_remove_jumps_la_stretch = []\n",
    "for sat in sat_t1:\n",
    "    d = get_satellite_data(remove_jumps_la_stretch_train,sat)\n",
    "    smape_remove_jumps_la_stretch.append(smape(d[feature_list].to_numpy(),d[target_list].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smape for orignal simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_original = []\n",
    "for sat in sat_t1:\n",
    "    d = get_satellite_data(data,sat)\n",
    "    smape_original.append(smape(d[feature_list].to_numpy(),d[target_list].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove jumps, stretch, then do LA\n",
    "\n",
    "First two pieces already in `remove_jumps_stretch` df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:37<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "alignment_model = LinearAlignment()\n",
    "stretch_la_df = pd.DataFrame([])\n",
    "for sat_id in tqdm(sat_t1):\n",
    "    try:\n",
    "        sat_data = get_satellite_data(remove_jumps_stretch, sat_id)\n",
    "        n_first = sat_data.shape[0] - sat_data['x'].isnull().sum()\n",
    "        index = sat_data.index\n",
    "        pred = pd.DataFrame(index = index)\n",
    "        sat_data.set_index(index)\n",
    "    except KeyError as e:\n",
    "        print(f'jump removal failed for satellite {sat_id}:\\t{type(e).__name__} {e}')\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    n_train = 4*len(sat_data) // 10\n",
    "    train_sat_data = sat_data[:n_train]\n",
    "    \n",
    "    pred['epoch'] = sat_data['epoch'].values\n",
    "    pred['t'] = sat_data['t'].values\n",
    "    pred['sat_id'] = sat_id\n",
    "    \n",
    "    try:\n",
    "        for feature_name in target_list:\n",
    "            alignment_model.fit(t=train_sat_data['epoch'].values,\n",
    "                                x=-train_sat_data[f'{feature_name}_sim'].values,\n",
    "                                gt=-train_sat_data[feature_name].values)\n",
    "            option1 = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "            alignment_model.fit(t=train_sat_data['epoch'].values,\n",
    "                                x= train_sat_data[f'{feature_name}_sim'].values,\n",
    "                                gt= train_sat_data[feature_name].values)\n",
    "\n",
    "            option2 = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "\n",
    "            if utils.smape(option1[n_train:n_first],sat_data[feature_name].values[n_train:n_first]) < utils.smape(option2[n_train:n_first],sat_data[feature_name].values[n_train:n_first]):\n",
    "                alignment_model.fit(t=sat_data['epoch'].iloc[:n_first].values,\n",
    "                                x=-sat_data[f'{feature_name}_sim'].iloc[:n_first].values,\n",
    "                                gt=-sat_data[feature_name].iloc[:n_first].values)\n",
    "\n",
    "                pred[f'{feature_name}_sim'] = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "            else:\n",
    "                alignment_model.fit(t=sat_data['epoch'].iloc[:n_first].values,\n",
    "                                x=sat_data[f'{feature_name}_sim'].iloc[:n_first].values,\n",
    "                                gt=sat_data[feature_name].iloc[:n_first].values)\n",
    "                pred[f'{feature_name}_sim']  = alignment_model.predict(t=sat_data['epoch'].values,\n",
    "                                                         x=sat_data[f'{feature_name}_sim'].values)\n",
    "\n",
    "            pred.loc[:,feature_name]=sat_data.loc[:, feature_name].values\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'linear alignment failed for satellite {sat_id}:\\t{type(e).__name__} {e}')\n",
    "        continue\n",
    "    stretch_la_df = stretch_la_df.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315183, 15)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_stretch_la_train = stretch_la_df.dropna()\n",
    "remove_jumps_stretch_la_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_jumps_stretch_la_test = stretch_la_df.loc[~stretch_la_df.index.isin\n",
    "                                           (remove_jumps_stretch_la_train.dropna().index)]\n",
    "remove_jumps_stretch_la_train.index.equals(data.index)\n",
    "#remove_jumps_stretch_la_test.index.equals(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_remove_jumps_stretch_la = []\n",
    "for sat in sat_t1:\n",
    "    d = get_satellite_data(remove_jumps_stretch_la_train,sat)\n",
    "    smape_remove_jumps_stretch_la.append(smape(d[feature_list].to_numpy(),d[target_list].to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare SMAPEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best choice `best_choice` of transformation for each satellite according to lowest smape in train data.\n",
    "\n",
    "Code is: \n",
    "\n",
    "1. original data \\\n",
    "    `data` (train) and `test_data` (test) <hr>\n",
    "    \n",
    "2. yes remove time jumps \\\n",
    "    `remove_jumps_train` and `remove_jumps` <hr>\n",
    "3. yes remove time jumps, yes LA \\\n",
    "    `remove_jumps_la_train` and `remove_jumps_la` <hr>\n",
    "4. yes remove time jumps, yes LA, yes stretch (in that order) \\\n",
    "    `remove_jumps_la_stretch_train` and `remove_jumps_la_stretch` <hr>\n",
    "5. yes remove time jumps, yes stretch \\\n",
    "    `remove_jumps_stretch_train` and `remove_jumps_stretch` <hr>\n",
    "6. yes remove time jumps, yes stretch, yes LA (in that order) \\\n",
    "    `stretch_la_df_train` and `stretch_la_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "satellites_and_smapes = [sat_t1, smape_original,smape_remove_jumps,smape_remove_jumps_la,\n",
    "                        smape_remove_jumps_la_stretch,smape_remove_jumps_stretch,\n",
    "                        smape_remove_jumps_stretch_la]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smapes_all = list(zip(sat_t1, smape_original,smape_remove_jumps,smape_remove_jumps_la,\n",
    "                        smape_remove_jumps_la_stretch,smape_remove_jumps_stretch,\n",
    "                        smape_remove_jumps_stretch_la))\n",
    "len(smapes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_choice = []\n",
    "for i in range(len(sat_t1)):\n",
    "    best_choice.append((smapes_all[i][0],smapes_all[i].index(min(smapes_all[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission with best transformation by satellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_choice_map = {1:test_data,2:remove_jumps_test,3:remove_jumps_la_test,\n",
    "                   4:remove_jumps_la_stretch_test,5:remove_jumps_stretch_test,\n",
    "                   6:remove_jumps_stretch_la_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>t</th>\n",
       "      <th>sat_id</th>\n",
       "      <th>x_sim</th>\n",
       "      <th>x</th>\n",
       "      <th>y_sim</th>\n",
       "      <th>y</th>\n",
       "      <th>z_sim</th>\n",
       "      <th>z</th>\n",
       "      <th>Vx_sim</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy_sim</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz_sim</th>\n",
       "      <th>Vz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>1.391213e+18</td>\n",
       "      <td>16102.001217</td>\n",
       "      <td>1</td>\n",
       "      <td>3451.926397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17799.333691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.699534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.691213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44.969238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.665829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>1.391214e+18</td>\n",
       "      <td>16102.015938</td>\n",
       "      <td>1</td>\n",
       "      <td>-1996.347386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16586.678857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2028.978297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.214549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44.581163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.527994</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>1.391215e+18</td>\n",
       "      <td>16102.030658</td>\n",
       "      <td>1</td>\n",
       "      <td>-7308.539847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14859.319228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3658.198746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.730742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44.193086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.390158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>1.391217e+18</td>\n",
       "      <td>16102.045378</td>\n",
       "      <td>1</td>\n",
       "      <td>-12210.632339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12732.228697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5151.846398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.239416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-43.805007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.252321</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>1.391218e+18</td>\n",
       "      <td>16102.060099</td>\n",
       "      <td>1</td>\n",
       "      <td>-16589.490670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10296.198786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6403.683205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.738143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-43.416926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.114484</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231060</th>\n",
       "      <td>1.393565e+18</td>\n",
       "      <td>16129.221544</td>\n",
       "      <td>597</td>\n",
       "      <td>3258.566123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85222.214779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6865.804981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.564234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.389517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.782024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231061</th>\n",
       "      <td>1.393572e+18</td>\n",
       "      <td>16129.306788</td>\n",
       "      <td>597</td>\n",
       "      <td>-11090.238004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85157.067499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7198.456304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.701828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.796423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.917122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231062</th>\n",
       "      <td>1.393579e+18</td>\n",
       "      <td>16129.392032</td>\n",
       "      <td>597</td>\n",
       "      <td>-25822.162385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82556.771379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7284.971503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.811503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.251472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.063917</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231063</th>\n",
       "      <td>1.393587e+18</td>\n",
       "      <td>16129.477275</td>\n",
       "      <td>597</td>\n",
       "      <td>-40755.890567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-77204.898038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7094.771615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.891778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.758888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.222861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231064</th>\n",
       "      <td>1.393594e+18</td>\n",
       "      <td>16129.562519</td>\n",
       "      <td>597</td>\n",
       "      <td>-55710.106089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-68885.019097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6597.277675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.941169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.322894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.394404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284071 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                epoch             t  sat_id         x_sim   x         y_sim  \\\n",
       "id                                                                            \n",
       "3927     1.391213e+18  16102.001217       1   3451.926397 NaN  17799.333691   \n",
       "3928     1.391214e+18  16102.015938       1  -1996.347386 NaN  16586.678857   \n",
       "3929     1.391215e+18  16102.030658       1  -7308.539847 NaN  14859.319228   \n",
       "3930     1.391217e+18  16102.045378       1 -12210.632339 NaN  12732.228697   \n",
       "3931     1.391218e+18  16102.060099       1 -16589.490670 NaN  10296.198786   \n",
       "...               ...           ...     ...           ...  ..           ...   \n",
       "1231060  1.393565e+18  16129.221544     597   3258.566123 NaN -85222.214779   \n",
       "1231061  1.393572e+18  16129.306788     597 -11090.238004 NaN -85157.067499   \n",
       "1231062  1.393579e+18  16129.392032     597 -25822.162385 NaN -82556.771379   \n",
       "1231063  1.393587e+18  16129.477275     597 -40755.890567 NaN -77204.898038   \n",
       "1231064  1.393594e+18  16129.562519     597 -55710.106089 NaN -68885.019097   \n",
       "\n",
       "          y        z_sim   z    Vx_sim  Vx     Vy_sim  Vy    Vz_sim  Vz  \n",
       "id                                                                       \n",
       "3927    NaN   336.699534 NaN -2.691213 NaN -44.969238 NaN  4.665829 NaN  \n",
       "3928    NaN  2028.978297 NaN -2.214549 NaN -44.581163 NaN  4.527994 NaN  \n",
       "3929    NaN  3658.198746 NaN -1.730742 NaN -44.193086 NaN  4.390158 NaN  \n",
       "3930    NaN  5151.846398 NaN -1.239416 NaN -43.805007 NaN  4.252321 NaN  \n",
       "3931    NaN  6403.683205 NaN -0.738143 NaN -43.416926 NaN  4.114484 NaN  \n",
       "...      ..          ...  ..       ...  ..        ...  ..       ...  ..  \n",
       "1231060 NaN  6865.804981 NaN -1.564234 NaN   0.389517 NaN -0.782024 NaN  \n",
       "1231061 NaN  7198.456304 NaN -1.701828 NaN   0.796423 NaN -0.917122 NaN  \n",
       "1231062 NaN  7284.971503 NaN -1.811503 NaN   1.251472 NaN -1.063917 NaN  \n",
       "1231063 NaN  7094.771615 NaN -1.891778 NaN   1.758888 NaN -1.222861 NaN  \n",
       "1231064 NaN  6597.277675 NaN -1.941169 NaN   2.322894 NaN -1.394404 NaN  \n",
       "\n",
       "[284071 rows x 15 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = best_choice_map[best_choice[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "(284071, 15)\n",
      "Index(['x_sim', 'y_sim', 'z_sim', 'Vx_sim', 'Vy_sim', 'Vz_sim'], dtype='object')\n",
      "(1901, 6)\n"
     ]
    }
   ],
   "source": [
    "submission_best_transformation = pd.DataFrame([])\n",
    "i=0\n",
    "for sat in sat_t1:\n",
    "  #  if i < 1:\n",
    "   #     print(i, best_choice[i][1])\n",
    "    d = best_choice_map[best_choice[i][1]]\n",
    "   # if i < 1:\n",
    "   #     print(d.shape)\n",
    "    d = d[d['sat_id']==sat]\n",
    "   # if i < 1:\n",
    "    #    print(d[feature_list].columns)\n",
    "    submission_best_transformation = submission_best_transformation.append(d[feature_list])\n",
    "    #if i < 1:\n",
    "     #   print(submission_best_transformation.shape)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_best_transformation.shape[0] - test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_best_transformation.index.equals(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_best_transformation.columns = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>3451.926397</td>\n",
       "      <td>17799.333691</td>\n",
       "      <td>336.699534</td>\n",
       "      <td>-2.691213</td>\n",
       "      <td>-44.969238</td>\n",
       "      <td>4.665829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>-1996.347386</td>\n",
       "      <td>16586.678857</td>\n",
       "      <td>2028.978297</td>\n",
       "      <td>-2.214549</td>\n",
       "      <td>-44.581163</td>\n",
       "      <td>4.527994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>-7308.539847</td>\n",
       "      <td>14859.319228</td>\n",
       "      <td>3658.198746</td>\n",
       "      <td>-1.730742</td>\n",
       "      <td>-44.193086</td>\n",
       "      <td>4.390158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>-12210.632339</td>\n",
       "      <td>12732.228697</td>\n",
       "      <td>5151.846398</td>\n",
       "      <td>-1.239416</td>\n",
       "      <td>-43.805007</td>\n",
       "      <td>4.252321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>-16589.490670</td>\n",
       "      <td>10296.198786</td>\n",
       "      <td>6403.683205</td>\n",
       "      <td>-0.738143</td>\n",
       "      <td>-43.416926</td>\n",
       "      <td>4.114484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x             y            z        Vx         Vy        Vz\n",
       "id                                                                          \n",
       "3927   3451.926397  17799.333691   336.699534 -2.691213 -44.969238  4.665829\n",
       "3928  -1996.347386  16586.678857  2028.978297 -2.214549 -44.581163  4.527994\n",
       "3929  -7308.539847  14859.319228  3658.198746 -1.730742 -44.193086  4.390158\n",
       "3930 -12210.632339  12732.228697  5151.846398 -1.239416 -43.805007  4.252321\n",
       "3931 -16589.490670  10296.198786  6403.683205 -0.738143 -43.416926  4.114484"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_best_transformation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submission_2020-02-02_13-35-01.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "submission_filename = 'submission_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "submission_best_transformation.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correctness of submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for sat in sat_t1:\n",
    "    ind = get_satellite_data(test_data,sat).index\n",
    "    df = submission_best_transformation\n",
    "    sub = df[df.index.isin(ind)]\n",
    "    b = best_choice_map[best_choice[i][1]]\n",
    "    sub2 = b[b.index.isin(ind)]\n",
    "    if sub.shape[0] != sub2.shape[0]:\n",
    "        print('Length does not match for satellite:',sat)\n",
    "    for dim in target_list:\n",
    "        if sub[dim].equals(other = sub2[dim +'_sim']) == False:\n",
    "            print(sat,dim)    \n",
    "    i+=1   \n",
    "#if correcly matched best transformation, expect no output here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split the train data set to train/test for RF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,col = 'sat_id',ratio = 0.8,targets = ['x','y','z','Vx','Vy','Vz']):\n",
    "    '''\n",
    "    train test split for our train data, \n",
    "    default, 80% train for each satellite, 20% test\n",
    "    '''\n",
    "    sat_list = df[col].unique()\n",
    "    train_df = pd.DataFrame([])\n",
    "    test_df = pd.DataFrame([])\n",
    "    for sat in sat_list:\n",
    "        sat_df = get_satellite_data(df,sat)\n",
    "        n = int(ratio*sat_df.shape[0])\n",
    "        train_df = train_df.append(sat_df[:n])\n",
    "        test_df = test_df.append(sat_df[n:])\n",
    "    Y_train = train_df[targets]\n",
    "    Y_test = test_df[targets]\n",
    "    X_train = train_df.drop(targets,axis=1)\n",
    "    X_test = test_df.drop(targets,axis=1)\n",
    "    return X_train, X_test, Y_train, Y_test       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking indices match\n",
    "for sat in X_train['sat_id'].unique():\n",
    "    if X_train[X_train['sat_id']==sat].index[-1] + 1 != X_test[X_test['sat_id']==sat].index[0]:\n",
    "        print(sat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_test.index != X_test.index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_train.index != X_train.index).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First remove time jumps and run linear alignment on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_track1 = test_data['sat_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list\n",
    "feat_sim = [feat+'_sim' for feat in features_list]\n",
    "feat_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = transf_df.copy()\n",
    "#print('shape',data2.shape)\n",
    "for feat in feat_sim:\n",
    "    data2[feat+'_shift'] = data2.groupby(['sat_id'])[feat].shift()\n",
    "    #print('shape',data2.shape)\n",
    "    data2[feat+'_diff'] = data2.groupby(['sat_id'])[feat].diff()\n",
    "    #print('shape',data2.shape)\n",
    "data2 = data2.fillna(0)\n",
    "#print(data2.isna().sum())\n",
    "#print('shape',data2.shape)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_la = [] #exclude from LA\n",
    "#no_la = [372,587,523,473,514] #satellites excluded from LA by Tanya\n",
    "la_list = [s for s in satellites_list if s not in no_la]\n",
    "len(la_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train separate model for each of 6 predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try VAR, first check stationarity with Augmented Dickey-Fuller test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "X = data[data['sat_id']==0]['x'].to_numpy()\n",
    "result = adfuller(X)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcSViye3JE8U"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('data/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_index = sub.id.values\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = transf_df.loc[sub_index,['x_sim', 'y_sim','z_sim','Vx_sim','Vy_sim','Vz_sim']]\n",
    "q.columns = ['x','y','z','Vx','Vy','Vz']\n",
    "# q = q.reset_index()\n",
    "q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(sub.x.iloc[2500:2900].values)\n",
    "\n",
    "plt.plot(q.x.iloc[2500:2900].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "submission_filename = 'submission_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "q.to_csv(submission_filename)\n",
    "print('Submission saved to {}'.format(submission_filename))\n",
    "\n",
    "q.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_lengths(t,x):\n",
    "    '''\n",
    "    Find cycle lengths; input t = time array or series and x = position or velocity\n",
    "    '''\n",
    "    spl = InterpolatedUnivariateSpline(t, x)\n",
    "    roots = spl.roots()\n",
    "    half_periods = np.diff(spl.roots())\n",
    "    periods = np.add.reduceat(half_periods, np.arange(0, len(half_periods), 2))\n",
    "    if len(half_periods)%2 != 0: #if odd # of observations, remove last (invalid) half period\n",
    "        periods = periods[:-1]\n",
    "    return periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[data.sat_id == 317]\n",
    "td = test_data[test_data.sat_id == 317]\n",
    "new = pd.concat([d,td],  axis = 0, sort = False)\n",
    "spl = InterpolatedUnivariateSpline(d['epoch'], d['x'])\n",
    "roots = spl.roots()\n",
    "plt.figure(figsize=(15, 5))\n",
    "#plt.plot(new['epoch'],new['x_sim'])\n",
    "plt.plot(d['epoch'],d['x'])\n",
    "plt.scatter(roots,[0]*len(roots));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[data.sat_id == 302]\n",
    "periods = cycle_lengths(d['epoch'],d['Vz'])\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(321)\n",
    "plt.plot(periods);\n",
    "\n",
    "d = data[data.sat_id == 303]\n",
    "periods = cycle_lengths(d['epoch'],d['Vz'])\n",
    "fig.add_subplot(322)\n",
    "plt.plot(periods);\n",
    "\n",
    "d = data[data.sat_id == 304]\n",
    "periods = cycle_lengths(d['epoch'],d['Vz'])\n",
    "fig.add_subplot(323)\n",
    "plt.plot(periods);\n",
    "\n",
    "d = data[data.sat_id == 305]\n",
    "periods = cycle_lengths(d['epoch'],d['Vz'])\n",
    "fig.add_subplot(324)\n",
    "plt.plot(periods);\n",
    "\n",
    "d = data[data.sat_id == 306]\n",
    "periods = cycle_lengths(d['epoch'],d['Vz'])\n",
    "fig.add_subplot(325)\n",
    "plt.plot(periods);\n",
    "\n",
    "d = data[data.sat_id == 307]\n",
    "periods = cycle_lengths(d['epoch'],d['Vz'])\n",
    "fig.add_subplot(326)\n",
    "plt.plot(periods);\n",
    "\n",
    "plt.subplots_adjust(top=2.92, bottom=0.08, left=0.30, right=1.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "prophet_model_exploration-Copy1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
